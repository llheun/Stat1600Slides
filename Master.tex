\documentclass[14pt]{beamer}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usetheme{CambridgeUS}
\usepackage[english]{babel}
%\definecolor{lred}{rgb}{1,0.5,0}
%\definecolor{lgray}{gray}{0.95}
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
%\usepackage[lmargin=3cm, rmargin=2cm]{geometry}    % See geometry.pdf to learn the layout options. There are lots.
%\geometry{letterpaper}                   % ... or a4paper or a5paper or ...
%\geometry{landscape}                % Activate for for rotated page geometry
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
%\usepackage{epstopdf}
%\usepackage{exsol, fancyvrb}   % Provides exercises and solutions.  See https://ctan.org/pkg/exsol.
%\usepackage{color}
\usepackage{verbatim}
%\usepackage{url}
%\usepackage{natbib}
%\usepackage{makeidx}

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Stat 1600}
% \subtitle{Overview and Descriptive Statistics}
\author{Loren Heun}
\institute{WMU}
\date{\today}

% \makeindex
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\frame{\titlepage}



%\maketitle

%\newpage

% % Copyright \copyright 2015 by Loren L. Heun at Western Michigan University \\ \newline
% All rights reserved \\[5mm]
% Reproduction or translation of any part of this work beyond that permitted by Sections 107 and 108 of the 1976 United States Copyright Act without permission of the copyright owner is unlawful.\\[5mm]
% A general introduction to statistics with an emphasis on data analysis and graphical presentation. Extensive use will be made of the computer to prepare results. Topics may include: data collection, sampling and experimentation, measurement issues, descriptive statistics, statistical graphics, normal distribution, cross-classified data, correlation and association, formal statistical inferences, and resampling methods.



%\tableofcontents


%!Rnw root = ../../Master.Rnw

\section{STAT 1600 Statistics and Data Analysis Slides}

\begin{frame}[fragile]{Statistics and Data Analysis}

Lecture 2 Knowledge and data

\end{frame}

\begin{frame}[fragile]{Outline}

Data Presentation \# 1

\begin{itemize}
\item Statistics and Data
\item Variable Types
\item Summarizing Categorical Data
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Knowledge and data}

\begin{itemize}
\item Step-by-step knowledge building
\item Some fallacies in interpreting evidence
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

1. Conceptualize the problem

\begin{itemize}
\item This is the problem of interest.  State it broadly.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

2. Operationalize the problem

\begin{itemize}
\item The investigator formulates specific questions to answer
\item What do you want to measure?  These will become our dependent variables.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

3. Design the Study

\begin{itemize}
\item How will you select your sample?
\item How many groups will you compare?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

4. Collect the Data

\begin{itemize}
\item What instrument or technique will you use to collect data?
\item Will you use a survey, questionnaire, interview, observation?
\item Are you measuring a variable that will require special equipment/technology?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

5. Analyze the Data

\begin{itemize}
\item Are you comparing means? Percentages?
\item Are differences statistically significant?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

6. Conclusions

\begin{itemize}
\item Do the results generalize to a larger population?
\item Did you show cause-and-effect or just associations?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

7. Disseminate results

\begin{itemize}
\item How are you sharing your results?  
\item News reports? 
\item Scientific journals? 
\item Etcâ€¦
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Step-by-step Knowledge Building }

\begin{itemize}
\item Conceptualize the problem -- broad wording
\item Operationalize the problem -- specific questions
\item Design the Study -- how to select samples
\item Collect the Data -- measurement instrument
\item Analyze the Data -- comparing what
\item Conclusions -- repeatability and generalization
\item Disseminate results -- presentation of results
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Example -- comparing wt loss program}

\begin{itemize}
\item Zone
  \begin{itemize}
  \item Balances carbohydrates, protein, fat
  \end{itemize}
\item Atkins
  \begin{itemize}
  \item Low carbohydrate, high fat, unrestricted calories
  \end{itemize}
\item LEARN
  \begin{itemize}
  \item Low fat, and based on national guidelines
  \end{itemize}
\item Ornish
  \begin{itemize}
  \item Low fat, high carbohydrate, unrestricted calories
  \end{itemize}
\end{itemize}

How are we going to design a study to compare these?
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

1. Conceptualize the problem

\begin{itemize}
\item Which weight loss program is most effective?
\item Which one is most healthy?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

2. Operationalize the problem

\begin{itemize}
\item How do we measure `effective' and `healthy?'
\item At what time point are we interested in measuring? In 2 weeks, 2 months, 2 years?
\item Are we comparing average weight loss or perhaps the percentage of people who lost 15 pounds or more?
\item How do we measure healthy?  LDL cholesterol reduction, BP reduction, Glucose levels?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

3. Design the Study

\begin{itemize}
\item Where are we recruiting our subjects?
\item How long will the study last?
\item Do they choose the diet or do we randomly assign them to it?
\item How do we ensure they stay on a diet?
\item What do we do with participants who go off the diet, do we eliminate them from the study?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

4. Collect the Data

\begin{itemize}
\item How many times will we measure their weights?
\item Are we taking blood samples? Urine samples? Are we sending samples to the lab?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

5. Analyze the Data

\begin{itemize}
\item Are there significant differences in average weight loss between the diet groups?
\item Are there differences in cholesterol, blood pressure, glucose levels or other biochemistry measures relating to health?
\item Are there differences in how well participants adhere to each diet plan?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

6. Conclusions

\begin{itemize}
\item After analyzing the results what do we conclude is the best diet? Why?
\item Can we generalize results to the larger population?
\item Are we sure weight loss can be attributed to the diet?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Building knowledge step-by-step}

7. Disseminate results

\begin{itemize}
\item How are we going to present the results?
\item What tables and graphs would make the study easy to read and understand?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Questioning results of a study}

{\small{
If we are reading the results of a study we need to be able to ask ourselves some questions:

\begin{itemize}
\item What is the long-term result (perhaps the results will differ if measurements are taken at longer time points)?
\item What was the sample and to what population are we trying to generalize the results (males, females, age, ethnic differences)?  We want to make sure we can generalize to the population outside of the study sample.
\item Was the sample size large enough to allow for generalizing to the outside population?
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Questioning results of a study}

There is variation in study design, and some studies are designed better than others.  We need to be able to judge the validity and reliability of a study.
\end{frame}

\begin{frame}[fragile]{Fallacies in interpreting evidence}

\begin{enumerate}
\item Lack of evidence
  \begin{itemize}
  \item ``No proof that the drug is unsafe.''
  \item This is flawed as a lack of evidence does not mean the contrary is true and that the drug is safe.
  \end{itemize}
\item Anecdotal evidence
  \begin{itemize}
  \item ``Testimonies of real people this worked for \dots''
  \item Infomercials.
  \item Existence does not mean prevalence.  Perhaps the drug or supplement worked for some people, but does that mean it is effective for the broader population?
  \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Fallacies in interpreting evidence}

\begin{itemize}
\item Correlation equals causation
  \begin{itemize}
  \item ``married people are happier than single people.''
  \item Did marriage cause the `happier' outcome?  Maybe happy people are the ones who tend to get married.
  \item Two things happening at the same time does not mean one causes the other.
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Examples of Wrong Reasoning Leading to Wrong Conclusions}

\begin{itemize}
\item Lack of evidence fallacy.  The fallacy lies in the reasoning that lack of evidence means the contrary is true.
\item Anecdotal evidence fallacy.  The fallacy lies in the reasoning that existence means prevalence.
\item Correlation equals causation fallacy.  The fallacy lies in the reasoning that ``two things happening together'' must mean one causes the other.
\end{itemize}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{STAT 1600 Statistics and Data Analysis Slides}

\begin{frame}[fragile]{Statistics and Data Analysis}

Ch 2.4 Summarizing  Numerical Data

\end{frame}

\begin{frame}[fragile]{Outline}

Data Presentation \#2  

\begin{itemize}
\item Summarizing Numerical Data
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Sorted Data List}

Payment (Rent or Mortgage), ACS Data:



140, 190, 200, 200, 220, 230, 250, 280, 290, 340, 340, 350, 370, 380, 380, 400, 420, 440, 450, 490, 500, 500, 500, 510, 530, 550, 560, 650, 670, 670, 700, 700, 700, 700, 710, 720, 740, 740, 750, 760, 770, 800, 850, 880, 900, 900, 910, 970, 990, 1000, 1000, 1100, 1200, 1200, 1200, 1200, 1200, 1300, 1400, 1400, 1500, 1800, 2400, 5200

\end{frame}

\begin{frame}[fragile]{Sorted Data List}

Payment (Rent or Mortgage), ACS Data:

140, 190, 200, 200, 220, 230, 250, 280, 290, 340, 340, 350, 370, 380, 380, 400, 420, 440, 450, 490, 500, 500, 500, 510, 530, 550, 560, 650, 670, 670, 700, 700, 700, 700, 710, 720, 740, 740, 750, 760, 770, 800, 850, 880, 900, 900, 910, 970, 990, 1000, 1000, 1100, 1200, 1200, 1200, 1200, 1200, 1300, 1400, 1400, 1500, 1800, 2400, 5200

MIN = smallest observation = 140 
\end{frame}

\begin{frame}[fragile]{Sorted Data List}

Payment (Rent or Mortgage), ACS Data:

140, 190, 200, 200, 220, 230, 250, 280, 290, 340, 340, 350, 370, 380, 380, 400, 420, 440, 450, 490, 500, 500, 500, 510, 530, 550, 560, 650, 670, 670, 700, 700, 700, 700, 710, 720, 740, 740, 750, 760, 770, 800, 850, 880, 900, 900, 910, 970, 990, 1000, 1000, 1100, 1200, 1200, 1200, 1200, 1200, 1300, 1400, 1400, 1500, 1800, 2400, 5200

MIN = smallest observation = 140 

typical payment = around 700

\end{frame}

\begin{frame}[fragile]{Sorted Data List}

Payment (Rent or Mortgage), ACS Data:

140, 190, 200, 200, 220, 230, 250, 280, 290, 340, 340, 350, 370, 380, 380, 400, 420, 440, 450, 490, 500, 500, 500, 510, 530, 550, 560, 650, 670, 670, 700, 700, 700, 700, 710, 720, 740, 740, 750, 760, 770, 800, 850, 880, 900, 900, 910, 970, 990, 1000, 1000, 1100, 1200, 1200, 1200, 1200, 1200, 1300, 1400, 1400, 1500, 1800, 2400, 5200

MIN = smallest observation = 140 

MAX = largest observation = 5200, an outlier  

typical payment = around 700

\end{frame}

\begin{frame}[fragile]{Outlier}

An observation that falls apart from the rest of the data

$\Rightarrow$ check for correctness  

Here,

{\small{
\begin{tabular}{@{} cccccc   @{}} \hline
Household & State & Bedrooms & Payment & Type & Income \\ \hline
28 & Michigan & 4 & 5200 & Mortgage & 358000 \\ \hline
\end{tabular}
}}

$\Rightarrow$ OK
\end{frame}

\begin{frame}[fragile]{Stem-and-Leaf Plot}

\begin{itemize}
\item See next slide and page 24 for two views of the payment data  (Mortgage \& Rent combined) using stem-and-leaf plots
\item See page 25 for the comparison of the payments of the two types,  Mortgage and Rent, using side-by-side stem-and-leaf plots (same  scale, i.e., same stem width)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Stem-and-Leaf Plot}

{\tiny{
\begin{verbatim}

  The decimal point is 2 digit(s) to the right of the |

   1 | 49
   2 | 0023589
   3 | 445788
   4 | 02459
   5 | 0001356
   6 | 577
   7 | 00001244567
   8 | 058
   9 | 00179
  10 | 00
  11 | 0
  12 | 00000
  13 | 0
  14 | 00
  15 | 0
  16 | 
  17 | 
  18 | 0


\end{verbatim}
}}

{\small{
Note: 140, the one (1) to the left of $|$ is the hundredths digit and the four (4) to the right of $|$ is the tens digit. }}  
\end{frame}

\begin{frame}[fragile]{Stem-and-Leaf Plot}

{\tiny{
\begin{verbatim}

  The decimal point is 2 digit(s) to the right of the |

   1 | 49
   2 | 0023589
   3 | 445788
   4 | 02459
   5 | 0001356
   6 | 577
   7 | 00001244567
   8 | 058
   9 | 00179
  10 | 00
  11 | 0
  12 | 00000
  13 | 0
  14 | 00
  15 | 0
  16 | 
  17 | 
  18 | 0


\end{verbatim}
}}

{\small{
Note: 190, the one (1) to the left of $|$ is the hundredths digit and the nine (9) to the right of $|$ is the tens digit. }}  
\end{frame}

\begin{frame}[fragile]{iClicker Question 2.4.1}

The stem-and-leaf display below shows the BMI (Body Mass Index) of  14 individuals. What number(s) does `2 $|$ 56' represent?


\begin{minipage}[ht]{4.5cm}

{\small{
\begin{enumerate}
\item 2.5 and 2.6
\item 25 and 26
\item 250 and 260
\item 256
\item None of the above
\end{enumerate}
}}
\end{minipage} \hfill
\begin{minipage}[ht]{7cm}

{\tiny{
\begin{verbatim}

  The decimal point is 1 digit(s) to the right of the |

  1 | 588
  2 | 11222334
  2 | 56
  3 | 1


\end{verbatim}
}}
\end{minipage}
\end{frame}

\begin{frame}[fragile]{Relative Frequency Table}

The data range is first divided into several (usually) equal-width class intervals and then we obtain the frequency/relative frequency of data  values contained in each class interval.

\begin{itemize}
\item Often has 5 to 15 intervals (depending on number of observations)  
\item Starting value of the first (i,e, left-most) interval = \underline{\phantom{xxxxx}}.
\item Settle boundary disputes (for example we may have intervals contain the left endpoint but not the right)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Relative Frequency Table}

{\scriptsize{
\begin{tabular}{@{} ccc @{}} \hline
Monthly Payment(\$)* & Frequency & Rel. freq.(\%) \\ \hline
0-200 & 2 & 3.2 \\
200-400 & 13 & 20.6 \\
400-600 & 12 & 19.0 \\
600-800 & 14 & 22.2 \\
800-1000 & 8 & 12.7 \\
1000-1200 & 3 & 4.8 \\
1200-1400 & 6 & 9.5 \\
1400-1600 & 3 & 4.8 \\
1600-1800 & 0 & 0 \\
1800-2000 & 1 & 1.6 \\
2000-2200 & 0 & 0 \\
2200-2400 & 0 & 0 \\
2400-2600 & 1 & 1.6 \\ \hline
Total     & 63 & 100 \\ \hline
\end{tabular}
}}

* Interval contain the left endpoint, but not the right
\end{frame}

\begin{frame}[fragile]{Histogram}

{\small{
A graphical display of the relative frequency table defined by the class  intervals \\
$\Rightarrow$ frequencies (or relative frequencies) are plotted as columns
}}

\begin{center}


\includegraphics[width=4cm]{figure/LBL2e-1} 


\end{center}
\end{frame}

\begin{frame}[fragile]{iClicker Question 2.4.2}

{\small{
The histogram below shows the BMI (Body Mass Index) of 15  individuals. The right inclusion rule was used in the construction of the  histogram. What class interval(s) occurs least frequently?
}}

\begin{minipage}[ht]{5cm}

{\small{
\begin{enumerate}
\item (25, 30]
\item (30, 35]
\item (20, 25]
\item (25, 30] and (30, 35]
\item Unknown
\end{enumerate}
}}
\end{minipage} \hfill
\begin{minipage}[ht]{6cm}


\includegraphics[width=3.5cm]{figure/LBL2f-1} 

\end{minipage}

\end{frame}

\begin{frame}[fragile]{Dotplot}

\begin{itemize}
\item Each observation is represented by a dot, repeated values are  stacked
upwards
\item Below is a comparison dotplot of the monthly payments from the two  types of payment:
\end{itemize}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=4cm]{chapters/chapter2/ext_figure/dotchart.png} % requires the graphicx package
   %\caption{example caption}
   %\label{fig:example}
\end{figure}
\end{frame}

\begin{frame}[fragile]{iClicker Question 2.4.3}

We summarize numerical data with all of the following EXCEPT:

\begin{enumerate}
\item Bar chart
\item Dotplot
\item Histogram
\item Scatterplot
\item Stem and leaf
\end{enumerate}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{STAT 1600 Ch 2.4.4 Box and Whisker Plot}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT 1600 \\
Ch 2.4.4 Box and Whisker Plot

\end{frame}

\begin{frame}[fragile]{Outline}

Summarizing Numerical Data, \#2  

\begin{itemize}
\item Box-and-Whisker Plot  
\item Symmetry and Skewness
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Box -and-whisker plot  (or Boxplot)}

\begin{minipage}[ht]{6cm}

{\small{
This is a graphical picture of the  distribution of quarters of the  data
}}
\end{minipage}
\begin{minipage}[ht]{5cm}


\includegraphics[width=5cm]{figure/LBL2Aa-1} 

\end{minipage}

{\footnotesize{
\begin{itemize}
\item \textbf{This shows the range of each of the four quarters of data:}  
\item MINimum to Q1 (upper boundary of first quarter): 140, 415
\item Median (upper boundary of second quarter, also known as Q2): 700  
\item Q3 is the upper boundary of the third quarter: 975
\item MAXimum is the largest of the ordered observations: 5200
\end{itemize}
}}

\end{frame}

\begin{frame}[fragile]{Five-number Summary}

Payment (Rent/Mortgage, outlier excluded), ACS Data
n = 63;	(n + 1)/4 = 16;	1st quarter of the data 

\vspace{3mm}

140, 190, 200, 200, 220, 230, 250, 280, 290, 340, 340, 350, 370, 380, 380, 400, 420, 440, 450, 490, 500, 500, 500, 510, 530, 550, 560, 650, 670, 670, 700, 700, 700, 700, 710, 720, 740, 740, 750, 760, 770, 800, 850, 880, 900, 900, 910, 970, 990, 1000, 1000, 1100, 1200, 1200, 1200, 1200, 1200, 1300, 1400, 1400, 1500, 1800, 2400, 5200

\vspace{3mm}

The range is from 140 to 415
\end{frame}

\begin{frame}[fragile]{Five-number Summary}

Payment (Rent/Mortgage, outlier excluded), ACS Data
n = 63;	(n + 1)/4 = 16;	2nd quarter of the data 

\vspace{3mm}

140, 190, 200, 200, 220, 230, 250, 280, 290, 340, 340, 350, 370, 380, 380, 400, 420, 440, 450, 490, 500, 500, 500, 510, 530, 550, 560, 650, 670, 670, 700, 700, 700, 700, 710, 720, 740, 740, 750, 760, 770, 800, 850, 880, 900, 900, 910, 970, 990, 1000, 1000, 1100, 1200, 1200, 1200, 1200, 1200, 1300, 1400, 1400, 1500, 1800, 2400, 5200

\vspace{3mm}

The range is from 415 to 700
\end{frame}

\begin{frame}[fragile]{Five-number Summary}

Payment (Rent/Mortgage, outlier excluded), ACS Data
n = 63;	(n + 1)/4 = 16;	3rd quarter of the data 

\vspace{3mm}

140, 190, 200, 200, 220, 230, 250, 280, 290, 340, 340, 350, 370, 380, 380, 400, 420, 440, 450, 490, 500, 500, 500, 510, 530, 550, 560, 650, 670, 670, 700, 700, 700, 700, 710, 720, 740, 740, 750, 760, 770, 800, 850, 880, 900, 900, 910, 970, 990, 1000, 1000, 1100, 1200, 1200, 1200, 1200, 1200, 1300, 1400, 1400, 1500, 1800, 2400, 5200

\vspace{3mm}

The range is from 700 to 975
\end{frame}

\begin{frame}[fragile]{Five-number Summary}

Payment (Rent/Mortgage, outlier excluded), ACS Data
n = 63;	(n + 1)/4 = 16;	4th quarter of the data 

\vspace{3mm}

140, 190, 200, 200, 220, 230, 250, 280, 290, 340, 340, 350, 370, 380, 380, 400, 420, 440, 450, 490, 500, 500, 500, 510, 530, 550, 560, 650, 670, 670, 700, 700, 700, 700, 710, 720, 740, 740, 750, 760, 770, 800, 850, 880, 900, 900, 910, 970, 990, 1000, 1000, 1100, 1200, 1200, 1200, 1200, 1200, 1300, 1400, 1400, 1500, 1800, 2400, 5200

\vspace{3mm}

The range is from 975 to 2400
\end{frame}

\begin{frame}[fragile]{Five-number Summary}

Payment (Rent/Mortgage, outlier excluded), ACS Data
n = 63;	(n + 1)/4 = 16;	In summary,

\begin{itemize} 
\item MIN = smallest observation = 140 
\item Q1  = 1st quartile = 400
\item MED = median (= 2nd quartile) = 700
\item Q3  = 3rd quartile = 970
\item MAX = largest observation = 2400
\item
\item MIN, Q1, MED, Q3, and MAX give five-number summary
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Five-number Summary}

Payment (Rent/Mortgage, outlier excluded), ACS Data
n = 63;	(n + 1)/4 = 16;	In summary,

\begin{itemize} 
\item 50\% of data values $\le$ MED
\item 50\% of data values $\ge$ MED
\item 25\% of data values $\le$ Q1
\item 75\% of data values $\ge$ Q1
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Computing Five-number Summary}

\begin{enumerate}
\item<1-> Sort data into a list of ordered values  
\item<2-> Find MIN and MAX
\item<3-> Determine the sample size (i.e., number of observations) n
\item<4-> Q1 = 0.25(n + 1)th ordered value
\item<5-> MED = 0.5(n + 1)th ordered value
\item<6-> Q3 = 0.75(n + 1)th ordered value
\item<7-> If a non-integer resulted in any computation of the quartiles  (Q1, MED, Q3) above, average the two adjacent ordered  values for the respective quartile
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Five-number Summary for Monthly Rent}

{\small{
Sorted monthly payments for Type = Rent (n = 20), ACS Data}}

\vspace{3mm}

140, 220, 250, 280, 340, 350, 380, 400, 490, 500, 560, 650, 670, 700, 700, 740, 760, 880, 910, 1200

{\small{
\begin{enumerate}
\item<1-> MIN = 140, MAX = 1200
\item<2-> 0.25(n + 1) = 5.25 and hence Q1 = average of 5th and 6th  ordered values = (340 + 350)/2 = 345
\item<3-> 0.5(n + 1) = 10.5 and hence MED = average of 10th and 11th  ordered values = (500 + 560)/2 = 530
\item<4-> 0.75(n + 1) = 15.75 and hence Q3 = average of 15th and 16th  ordered values = (700 + 740)/2 = 720
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 2.4.4.1}

 In general, the middle 50\% of data values are bounded by what  statistics?
\begin{enumerate}

\item The first quartile and the median.
\item The first quartile and the third quartile.
\item The median and the third quartile.
\item The median and the maximum.
\item The minimum and the maximum.
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 2.4.4.2}

Given the 5-Number summary (MIN, Q1, Q2, Q3, and MAX) of any  data set, approximately 75\% of data values are at or above what  statistic?

\begin{enumerate}
\item The median.
\item The first quartile.
\item The third quartile.
\item The maximum.
\item The minimum.
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Box-and-whisker Plot}


\includegraphics[width=5cm]{figure/LBL2Ac-1} 


\vspace{-8mm}

\begin{itemize}
\item<1-> Draw a horizontal axis covering data range
\item<2-> Draw a box with edges at Q1 and Q3
\item<3-> Draw within the box, a line located at MED
\item<4-> Draw `fences' (lines) at the MIN and MAX
\item<5-> Draw `whiskers' extending from the edges of the box to the MIN and MAX
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Comparison Boxplots}


\includegraphics[width=6cm]{figure/LBL2Ad-1} 

\end{frame}

\begin{frame}[fragile]{Symmetry/Skewness}

Left-skewed
{\footnotesize{
\begin{verbatim}


  The decimal point is 1 digit(s) to the right of the |

   4 | 0
   5 | 5
   6 | 2
   7 | 
   8 | 17
   9 | 2445
  10 | 011245569
  11 | 58


\end{verbatim}
}}
\end{frame}

\begin{frame}[fragile]{Symmetry/Skewness}

Symmetric

{\footnotesize{
\begin{verbatim}


  The decimal point is 1 digit(s) to the right of the |

   4 | 7
   5 | 35
   6 | 005
   7 | 00112
   8 | 467899
   9 | 0199
  10 | 14
  11 | 1


\end{verbatim}
}}
\end{frame}

\begin{frame}[fragile]{Symmetry/Skewness}

Right-skewed

{\footnotesize{
\begin{verbatim}


  The decimal point is 1 digit(s) to the right of the |

   4 | 58
   5 | 011245569
   6 | 2445
   7 | 17
   8 | 
   9 | 2
  10 | 5
  11 | 0


\end{verbatim}
}}
\end{frame}

\begin{frame}[fragile]{Symmetry/Skewness, continued}

\begin{itemize}
\item<1-> \textbf{Symmetric:} data shape in two mirror-imaged halves  
\item<2-> \textbf{Right-skewed:} long right tail
\item<3-> \textbf{Left-skewed:} long left tail
\item<4-> \textbf{Symmetry/Skewness} can be detected by inspecting the stem-and-leaf plot (first turn it  counter-clockwise 90 degrees), histogram, dotplot, or boxplot  (median is half way from the edges of the box, whiskers on two sides of equal length)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{iClicker Question 2.4.4.3}

The stem-and-leaf displays of two data sets are given below. Describe  the shape of these two data sets.

\vspace{3mm}

\begin{minipage}[ht]{7.5cm}

\begin{enumerate}
\item 1. symmetric; 2. left skewed
\item 1. right skewed; 2. symmetric
\item 1. symmetric; 2. symmetric
\item 1. left skewed; 2. left skewed
\item 1. symmetric; 2. right skewed
\end{enumerate}
\end{minipage}
\begin{minipage}[ht]{2cm}

{\footnotesize{
\begin{tabular}{@{} r|l @{}} \hline
 & Set 1 \\ \hline
1 & 599 \\
2 & 0113 \\
3 & 669 \\ \hline
\end{tabular}

\begin{tabular}{@{} r|l @{}} \hline
& Set 2 \\ \hline
0 & 1223466 \\
1 & 0015 \\
2 & 9 \\ \hline
\end{tabular}
}}
\end{minipage}
\end{frame}

\begin{frame}[fragile]{iClicker Question 2.4.4.4}

Describe the shape of the box-and-whisker plot (boxplot) below.

\begin{minipage}[ht]{5cm}

{\small{
\begin{enumerate}
\item Symmetric
\item Right skewed
\item Left skewed
\item right and left skewed
\item None of the above
\end{enumerate}
}}
\end{minipage}
\begin{minipage}[ht]{5.5cm}
  

\includegraphics[width=5cm]{figure/LBL2Ae-1} 

\end{minipage}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{STAT 1600 Ch 2.4.4 Box and Whisker Plot}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT 1600 \\
Ch. 3 Estimates of Center

\end{frame}

\begin{frame}[fragile]{Outline}

Summarizing Numerical Data, \#3

\begin{itemize}
\item Location and Spread 
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Importance of Location and Spread}


\includegraphics[width=6cm]{figure/LBL3a-1} 


\vspace{-3mm}

{\footnotesize{
\begin{itemize}
\item<1-> The central \textit{location} of Rent appears to be smaller than that of Mortgage
\item<2-> Moreover, the \textit{spread} of Rent appears to be smaller than that of  Mortgage, i.e., Rent payment is less scattered (or less variable)  than that of Mortgage
\item<3-> But how do we quantify such comparisons?  $\Rightarrow$ through \textbf{location} and \textbf{spread} measures
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Outline}

Summarizing Numerical Data, \#3

\begin{itemize}
\item Location and spread
  \begin{itemize}
  \item Location and spread
  \end{itemize}
\item Estimates of Center
  \begin{itemize}
  \item Estimating Average Value
  \item The Sample Means
  \item The Trimmed Mean
  \item The Median of Pairwise Averages
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{How do you estimate the average rental}

Based on the following random sample of 2-bedroom apartments in Kalamazoo area

\vspace{3mm}



  140, 1200, 250, 340, 760, 700, 740, 490, 500, 880
  
\vspace{3mm}

  How do you measure the (central) location of such rentals?

\end{frame}

\begin{frame}[fragile]{Sample Mean is an Est. of Pop. Mean}

\begin{itemize}
\item<1-> The sample mean (i.e., average of the sample) is denoted by $\bar{X}$
\item<2-> and is the arithmatic average of data values  i.e.,
\item<3->
\begin{equation*}
\bar{X} = \frac{\texttt{sum of data values}}{\texttt{sample size}}
\end{equation*}
\item<4-> (2-bedroom appartment rental example)
\item<5->
\begin{equation*}
\bar{X} = \frac{140 + 1200 + \cdots + 880}{10} = 600
\end{equation*}
\end{itemize}

\end{frame}
 
\begin{frame}[fragile]{Sample Mean is an Est. of Pop. Mean}

\begin{itemize}
\item<1-> That is, the average rent for 2-bedroom apartments in  Kalamazoo area is \$ 600 in our sample
\item<2-> This is not to be interpreted as the actual \textit{population average}  (i.e., the actual average rent of all 2-bedroom apartments in  the entire Kalamazoo area)
\item<3-> It is subject to \textit{sampling error}
\item<4-> It likely missed the true population mean \\ (denoted $\mu$), by $| \bar{X} - \mu |$,  the \textit{sampling error}.
\end{itemize}

\end{frame}

\begin{frame}[fragile]{The Sample Median}



{\footnotesize{
\begin{itemize}
\item<1-> an alternative to the sample mean as a measure of location

\item<1-> Recall that the median is the 0.5(n + 1)th ordered data value

\item<1-> Sorted list of Kalamazoo 2-bedroom rental data

\vspace{3mm}

140, 250, 340, 490, 500, 700, 740, 760, 880, 1200
\item<2->
\begin{equation*}
0.5(n + 1) = 0.5 \times 11 = 5.5
\end{equation*}

\item<3-> 5.5 is in-between 5 and 6
\item<4-> Hence, MED = average of 5th \& 6th ordered values
\item<5->
\begin{equation*}
\tilde{x} = \frac{ 500 + 700 }{2} = 600
\end{equation*}
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 3.1.1}


The fuel efficiency (MPG) of 5 Japanese made cars are listed below

\begin{center}
27.5, 27.2, 34.1, 29.5, 31.8
\end{center}

What is the median MPG?

\begin{enumerate}
\item 29.5
\item 34.1
\item 30.50
\item 28.5
\item 27.5
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Sample Mean versus Sample Median}

\begin{itemize}
\item<1-> Sample mean is sensitive to outliers
\item<2-> Sample median is \textit{insensitive} to outliers
\item<3-> In the Kalamazoo apartment rental data, what if the smallest value \$ 140 is replaced by \$100?
\item<4-> The MED remains unchanged (\$ 600) but $\bar{X} = 596$, down by from the original data (\$ 600).
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Sample Mean versus Sample Median}

\begin{itemize}
\item Looking at another example:
\item Let's say we have a dataset of the following:  
\item Data: 5, 10, 17, 20, 25
\item Mean: \textbf{15.4}; Median:17
\item Data: 5, 10, 17, 20, 40
\item Mean: \textbf{18.4};  Median: 17
\end{itemize}

We can see the median has not been affected by the outlier, whereas the  mean has been affected.

\end{frame}

\begin{frame}[fragile]{The Trimmed Mean}


{\small{
\begin{itemize}
\item<1-> The Trimmed Mean is less sensitive to outliers when compared with sample mean  
\item<2-> 10\% trimmed mean = mean of data with lowest 10\% values and  highest 10\% values excluded = mean of middle 80\% values
\item<3-> in Kalamazoo apartment rental data, 10\% of n = 10 is 1 ($n \times 0.1 = 1$)

250, 340, 490, 500, 700, 740, 760, 880
% $500	$500	$525	$555	$635	$650	$670	$675	$750	$800
\item<4-> Hence, 10\% trimmed mean, denoted $\bar{X}_{tr}$, is computed by
\begin{eqnarray*}
\bar{X}_{tr} &=& \frac{250+340+490+500+700+740+760+880}{8} \\
     &=&582.5
\end{eqnarray*}
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{The Trimmed Mean -- cont'd}

\begin{itemize}
\item<1-> If $n \times 0.1$ is not an integer, round it up. E.g., if $n = 23$ such that  $n \times 0.1 = 2.3$ then exclude the 3 lowest values and the 3 highest values, thus computing the trimmed mean as the  average of 17 ($= 23 - 3 - 3$) middle values to ensure at least  10\% protection (against outlying values at each end)

\item<2-> The dataset must be ordered.
\end{itemize}

\end{frame}

\begin{frame}[fragile]{The Median of Pairwise Averages}

\begin{itemize}
\item The median of pairwise averages is another  compromise between the mean and the median.
\item We replace observations by pairwise averages of  those observations.
\item Next we take the median of those.
\item Also make sure to pair each observation with  itself!
\item Proceed in the following pattern as laid out on the  next slide.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{The Median of Pairwise Averages}

\begin{table}[ht]
\centering
{\tiny{
\begin{tabular}{@{}cccccccccc @{}} 
$\frac{500+500}{2}$ & $\frac{500+500}{2}$ & $\frac{500+525}{2}$ & $\frac{500+555}{2}$ & $\frac{500+635}{2}$ & $\frac{500+650}{2}$ & $\frac{500+670}{2}$ & $\frac{500+675}{2}$ & $\frac{500+750}{2}$ & $\frac{500+800}{2}$ \\
     & $\frac{500+500}{2}$ & $\frac{500+525}{2}$ & $\frac{500+555}{2}$ & $\frac{500+635}{2}$ & $\frac{500+650}{2}$ & $\frac{500+670}{2}$ & $\frac{500+675}{2}$ & $\frac{500+750}{2}$ & $\frac{500+800}{2}$ \\
     & & $\frac{525+525}{2}$ & $\frac{525+555}{2}$ & $\frac{525+635}{2}$ & $\frac{525+650}{2}$ & $\frac{525+670}{2}$ & $\frac{525+675}{2}$ & $\frac{525+750}{2}$ & $\frac{525+800}{2}$ \\
     & & & $\frac{555+555}{2}$ & $\frac{555+635}{2}$ & $\frac{555+650}{2}$ & $\frac{555+670}{2}$ & $\frac{555+675}{2}$ & $\frac{555+750}{2}$ & $\frac{555+800}{2}$ \\
     & & & & $\frac{635+635}{2}$ & $\frac{635+650}{2}$ & $\frac{635+670}{2}$ & $\frac{635+675}{2}$ & $\frac{635+750}{2}$ & $\frac{635+800}{2}$ \\
     & & & & & $\frac{650+650}{2}$ & $\frac{650+670}{2}$ & $\frac{650+675}{2}$ & $\frac{650+750}{2}$ & $\frac{650+800}{2}$ \\
     & & & & & & $\frac{670+670}{2}$ & $\frac{670+675}{2}$ & $\frac{670+750}{2}$ & $\frac{670+800}{2}$ \\
     & & & & & & & $\frac{675+675}{2}$ & $\frac{675+750}{2}$ & $\frac{675+800}{2}$ \\
     & & & & & & & & $\frac{750+750}{2}$ & $\frac{750+800}{2}$ \\ 
     & & & & & & & & & $\frac{800+800}{2}$ \\
\end{tabular}
}}
\end{table}

{\scriptsize{
\begin{itemize}
\item averaging 1st obs with itself = (500 + 500) / 2 = 500,
\item averaging 1st obs with 2nd obs = (500 + 500) / 2 = 500, and so on ...  
\item averaging 2nd obs with itself = (500 + 500) / 2 = 500, and so on ...  
\item and so on ...
\item median of 55 (= .5(n + 1)/2) pairwise averages = 28th (0.5(55 + 1) = 28)  ordered pairwise average = \$625.0.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Robustness of Est. of Central Location}

\begin{itemize}
\item Recall that an estimate is robust if it is insensitive to outliers.
\item \textbf{Robust} = resistant to errors
\item The sample mean is NOT robust. That is, it is sensitive to  outliers.
\item The sample median and the median of pairwise averages are  robust.
\item The trimmed means are more robust than the mean but less  robust than the median. Trimmed means with higher trimmed  percentage are more robust.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Clicker Question 3.1.2}

For estimates of central location, which of the following statements is  true?

\begin{enumerate}
\item Median, mean, and the median of pairwise averages are  robust.
\item Median, 20\% trimmed mean, and mean are robust.
\item Mean and the median are not robust.
\item Median and the median of pairwise averages are robust.
\item All statements above are incorrect.
\end{enumerate}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{STAT 1600 Ch 3.2 Estimates of Spread}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT 1600 \\
Ch 3.2 Estimates of Spread 

\end{frame}

\begin{frame}[fragile]{Outline}

Estimates of Spread  

\begin{itemize}
\item Estimates of Spread
\item The Sample Standard Deviation
\item Effect of Multiplication/Addition by a Constant 
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Estimates of Spread }

(or Uncertainty, Variation)

\begin{itemize}
\item<1-> An estimate of spread is a measure of uncertainty, or  variation, or `give or take'
\item<2-> When two or more comparable data sets (comparable means data sets are of same type/same unit of numerical  measurements) are compared, the one with the smallest spread has the least uncertainty around the estimate of center (i.e., least  scattered)
\item<3-> Estimates of spread are non-negative
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Estimates of Spread, Cont'd}

 i.e., 
 
\begin{itemize} 
\item<1-> The standard deviation (SD) is typically used as a `give or  take' number in describing the spread of a dataset 
\item<2->
\begin{equation*}
\texttt{Sample SD} = s = \sqrt{ \frac{ \sum (X - \bar{X})^2}{n - 1}} = \sqrt{ \frac{SS}{n -1}}
\end{equation*}
\end{itemize}
\end{frame}



\begin{frame}[fragile]{The Sample Standard Deviation (SD)}

\begin{minipage}[ht]{5cm}

{\footnotesize{
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:49 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Rent & Diff & Diff Sqd \\ 
  \hline
1 & 140 & -460 & 211600 \\ 
  2 & 1200 & 600 & 360000 \\ 
  3 & 250 & -350 & 122500 \\ 
  4 & 340 & -260 & 67600 \\ 
  5 & 760 & 160 & 25600 \\ 
  6 & 700 & 100 & 10000 \\ 
  7 & 740 & 140 & 19600 \\ 
  8 & 490 & -110 & 12100 \\ 
  9 & 500 & -100 & 10000 \\ 
  10 & 880 & 280 & 78400 \\ 
   \hline
\end{tabular}
\end{table}

}}

\end{minipage}
\begin{minipage}[ht]{6cm}

{\footnotesize{
\begin{itemize}
\item<1-> Step 1. Compute $\bar{x} = 600$
\item<2-> Step 2. Calculate Diff, i.e., how much an obs. `missed by' the average, (i.e., deviation).
\item<3-> Step 3. Square the `missed by' differences.
\item<4-> Step 4. Add all the squared `missed by' differences, i.e., SS
\item<5-> Step 5. Take the square-root of $\frac{SS}{n - 1}$ to get SD

\begin{equation*}
SD = \sqrt{ \frac{\ensuremath{9.174\times 10^{5}}}{ 10 - 1 }} = 319.3
\end{equation*}

\end{itemize}
}}
\end{minipage}

\end{frame}

\begin{frame}[fragile]{Interpretation of SD}



{\small{
\begin{table}
\caption{Bowling Example}
\begin{tabular}{@{} lc | c c @{}} \hline
Games & Scores & Mean & SD \\ \hline
First games & 163, 231, 224, 238, 279, 239, 226 & 228.6 & 34.34 \\
Last games  & 246, 244, 247, 248, 237, 258, 246 & 246.6 & 6.21 \\ \hline
\end{tabular}
\end{table}

Scores of Walter Ray Williams Jr. in 2008 bowling  tournament, Indiana

}}
\end{frame}

\begin{frame}[fragile]{Interpretation of SD}

{\footnotesize{
Scores of Walter Ray Williams Jr. in 2008 bowling  tournament, Indiana 


\includegraphics[width=6cm]{figure/LBLAc-1} 


\begin{itemize}
\item Bigger swings (larger SD) in earlier games and scored typically lower  (smaller Mean)
\item He played consistently (smaller SD) in later games, and typically with  better scores (larger Mean)
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Sample Standard Deviation is Not Robust}

As an estimate of the spread of a data set, the sample standard  deviation \textbf{is sensitive to outliers}.

\end{frame}

\begin{frame}[fragile]{iClicker Question 3.2.1}

The fuel efficiency (MPG) of 5 Japanese made cars are listed below

27.5,	27.2,	34.1,	29.5,	31.8

Ignoring any rounding error, what is the sum of all the deviations (MPG  for Japanese made cars) from the mean MPG for Japanese made  cars?

\begin{enumerate}
\item 9.38
\item 4.19
\item 0.00
\item -4.19
\item 30.58
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 3.2.2}

Recall that an estimate is robust if it is insensitive to outliers. Which of  the following statements is true.

\begin{enumerate}
\item The sample mean and the standard deviation are robust.
\item The sample mean is robust but the standard deviation is  not.
\item The sample mean is not robust but the standard deviation  is.
\item The sample mean and the standard deviation are not  robust.
\item None of the previous statements is true.
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Effect of Multiplication/Addition by a Constant}



\begin{center}
apartment rental example
\end{center}

\begin{itemize}
\item<1-> Recall that the mean and SD are \$ $600 \pm 319.3$ \\ ($\pm$ means `give or take')
\item<2-> Get a roommate and pay half the rent: \$ $300 \pm 159.6$ %$323  Â± $52
\item<3-> No roommate but has contribution of \$100 per month from parents: $300 \pm 319.3$    % $526 Â± $104
\end{itemize}
\end{frame}

\begin{frame}[fragile]{General Rules}

\begin{itemize}
\item<1-> when a constant is \textbf{added to/subtracted from} each data  value, the same thing happens to the average, but the SD  remains unchanged,
\item<2-> when each data value is \textbf{multiplied or divided} by a positive  constant, the same thing happens to both the average and  the SD.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{General Rules}

\begin{minipage}[ht]{5cm}

{\small{
Eg. data: 1, 2, 3

\begin{tabular}{@{} ccc @{}} \hline
X & Diff & Sqd \\ \hline
1 & -1 & 1 \\
2 & 0 & 0 \\
3 & 1 & 1 \\ \hline
$\bar{x}=2$ & 0 & $SS=2$ \\ \hline
\end{tabular}

\begin{equation*}
SD = \sqrt{ \frac{2}{(3-1)}} = 1
\end{equation*}
}}
\end{minipage}
\begin{minipage}[ht]{5cm}
{\small{
Eg. data: 3, 4, 5 (added 2)

\begin{tabular}{@{} ccc @{}} \hline
X & Diff & Sqd \\ \hline
3 & -1 & 1 \\
4 & 0 & 0 \\
5 & 1 & 1 \\ \hline
$\bar{x}=4$ & 0 & $SS=2$ \\ \hline
\end{tabular}

\begin{equation*}
SD = \sqrt{ \frac{2}{(3-1)}} = 1
\end{equation*}
}}
\end{minipage}

Notice here the mean increased from 2 to 4, yet the SD did not change.

\end{frame}

\begin{frame}[fragile]{General Rules}

\begin{minipage}[ht]{5cm}

{\small{
Eg. data: 1, 2, 3

\begin{tabular}{@{} ccc @{}} \hline
X & Diff & Sqd \\ \hline
1 & -1 & 1 \\
2 & 0 & 0 \\
3 & 1 & 1 \\ \hline
$\bar{x}=2$ & 0 & $SS=2$ \\ \hline
\end{tabular}

\begin{equation*}
SD = \sqrt{ \frac{2}{(3-1)}} = 1
\end{equation*}
}}
\end{minipage}
\begin{minipage}[ht]{5cm}
{\small{
Eg. data: 2, 4, 6 (times 2)

\begin{tabular}{@{} ccc @{}} \hline
X & Diff & Sqd \\ \hline
2 & -2 & 4 \\
4 & 0 & 0 \\
6 & 2 & 4 \\ \hline
$\bar{x}=4$ & 0 & $SS=8$ \\ \hline
\end{tabular}

\begin{equation*}
SD = \sqrt{ \frac{4}{(3-1)}} = 2
\end{equation*}
}}
\end{minipage}

In this second example, multiplying by 2 the mean doubled AND the SD doubled.

\end{frame}

\begin{frame}[fragile]{iClicker Question 3.2.3}

Compute the mean given the following data:

8, 12, 15, 22, 28

\begin{enumerate}
\item 5
\item 10
\item 15
\item 17
\item 20
\end{enumerate}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{STAT1600 Ch 4 Threats to Valid Comparisons}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT1600 \\ Ch 4 Threats to Valid Comparisons

\end{frame}

\begin{frame}[fragile]{Outline}

Threats to Valid Comparisons  

\begin{itemize}
\item Hidden Confounder
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Hidden Confounder}

Lower Extremity Fractures Example

In the study of `Lower extremity fractures in motor vehicle collisions:  Influence of direction of impact and seatbelt use,' one of the  conclusions is of interest: there was a higher incidence of lower  extremity fracture among women.

\end{frame}

\begin{frame}[fragile]{Lower Extremity Fractures}

Wrong assumptions may lead to wrong conclusions

by falsely assuming that gender \textbf{causes} higher/lower leg fractures, one  may reach these \textbf{false conclusions} about the study outcome `women  have higher rates of leg fractures'

\begin{itemize}
\item because they drive faster?  
\item apply brakes more slowly?  
\item have weaker bones?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Lower Extremity Fractures}

{\small{
A follow-up study titled `the role of driver gender and height'

turns out that \textbf{height} was the culprit.\\
Because \textbf{height} and \textbf{gender} have a strong link, a false conclusion  can result from a false assumption.\\
The pathway graph below describes the true relationship:

\vspace{3mm}

\begin{tabular}{@{} lllll @{}} 
\texttt{Confounder} & \texttt{Height} & $\Rightarrow$ & \texttt{Leg Fracture} & \texttt{Outcome} \\
\texttt{(actual cause)} & $\updownarrow$ &  & \\
\texttt{Prob cause} &\texttt{Gender} & &
\end{tabular}

\vspace{3mm}

$\updownarrow$  Means `association' or `probable cause' \\
$\Rightarrow$  Means `cause-and-effect'
}}
\end{frame}

\begin{frame}[fragile]{Lower Extremity Fractures}

\begin{tabular}{@{} lllll @{}} 
 & \texttt{Height} & $\Rightarrow$ & \texttt{Leg Fracture}  \\
\texttt{pathway graph :} & $\updownarrow$ &  & \\
 &\texttt{Gender} & &
\end{tabular}

\begin{itemize}
\item outcome variable: leg fracture.
\item probable cause: gender.
\item confounder or confounding variable: the hidden variable height.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Confounding Variable or Confounder}

A \textbf{confounder} is a third variable that is associated with both the probable cause and  the \textbf{outcome}.

\begin{itemize}
\item \textit{Overlooking} its existence can lead us to drawing a \textit{wrong  conclusion} about the cause-and-effect relationship.
\item Hidden confounders are one of the biggest sources of (often  unknowingly) \textit{invalid comparisons}. One could end up comparing  apples to oranges! (Note: women as a group are shorter than men!)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Lower Extremity Fractures, cont'd}

Potential confounders other than height includes 

\begin{itemize}
\item weight,  
\item none/light/heavy smoker, 
\item alcohol consumption, 
\item short/long hair,  
\item wearing higher heels or not, 
\item ..., etc.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{iClicker Question 4.1}

According to ``Cumulative Use of Strong Anticholinergics and Incident  Dementia'' (JAMA, March 2015), from 10 years of tracking older adults  and their use of anticholinergic drugs (meant to reduce symptoms of  allergies, inability to sleep, anxiety, depression and bladder over-activity), the risk of Alzheimer's was 63 percent higher. Which of  the following is the \textbf{outcome variable} (response)?

\begin{enumerate}
\item use of anticholinergic drugs
\item risk of Alzheimer's
\item hidden variables such as high blood pressure
\item none of the previous
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 4.2}

According to ``Cumulative Use of Strong Anticholinergics and Incident  Dementia'' (JAMA, March 2015), from 10 years of tracking older adults  and their use of anticholinergic drugs (meant to reduce symptoms of  allergies, inability to sleep, anxiety, depression and bladder over-activity), the risk of Alzheimer's was 63 percent higher. Which of  the following is the \textbf{probable cause}?

\begin{enumerate}
\item use of anticholinergic drugs
\item risk of Alzheimer's
\item hidden variables such as high blood pressure
\item none of the previous
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Outline}

Threats to Valid Comparisons  

\begin{itemize}
\item[1] Hidden Confounder
\item[2] In the Headlines
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Examples In the Headlines}

\begin{itemize}
\item<1-> Smoking `causes' lung cancer. True? Having lung cancer or not is  the outcome variable, smoking is probable cause, potential  confounders abound. (see textbook)
\item<2-> not true for a single study or a few studies.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Examples In the Headlines}

\begin{itemize}
\item<1-> ``Older Viagra Users More Likely to Get STDs'' -- the Chicago Sun  Times and the like. See critiques by Rebecca Goldin and Jing  Peng in August 2010 from  \texttt{http://www.stats.org} titled `If you  take Viagra, will you get an STD?' Pathway graph for this is `person type' (i.e. lifestyle) is a confounder which is the cause (or surrogate of causes)
\item<2-> `taking ED drugs or not' is only a probable cause
\end{itemize}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{STAT1600 Ch 5 Study Designs}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT1600 \\ Ch 5 Study Designs

\end{frame}

\begin{frame}[fragile]{Outline}

Study Designs  

\begin{itemize}
\item Randomized Trials
\item Double-blind Randomized Controlled Trials  
\item Observational Studies
\item iClicker Questions
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Diet Comparison Example}

The diet comparison example ``Comparison of the Atkins, Zone,  Ornish, and LEARN Diets for Change in Weight and Related Risk  Factors Among Overweight Premenopausal Women The A TO Z  Weight Loss Study: A Randomized Trial'' by C.D. Gardner, et al.  (JAMA, Vol. 297, pp. 969â€“977, March 2007) is a good example of  \textbf{randomized trials}.

An important characteristic of the experiment is that the comparison  groups are similar to each other in all aspects, \textbf{except for the  treatment} (see Table 5.1 on page 79). Hence such experiment offers  fair comparison of the treatment among the four diet groups.
\end{frame}

\begin{frame}[fragile]{Randomization and Randomized Trials}

\begin{itemize}
\item<1-> In a randomized trial, subjects entering the trial in a randomized  fashion (using virtual roll of a die) into one of several treatment groups.  This process is called:

\item<2-> Randomization

\item<3-> the best way to safeguard against potential confounders so that the  comparison groups are similar in all factors except for the treatment  itself.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Randomized Controlled Experiment (or Trial)}

is a randomized experiment in which one of the comparison groups is  a control group or placebo group.
\end{frame}

\begin{frame}[fragile]{Double-blind Randomized Controlled Trial}

is a randomized controlled trial in which neither doctor (the  experimenter) nor patient (experimental subject) knows what treatment  the patient receives.

\begin{itemize}
\item<1-> done by giving the patient a pill that looks/smells... like the  treatment pill, but is actually an inert pill or placebo.
\item<2-> Blinding achieves additional protection against bias.
\item<3-> All groups have the same frame of mind (as opposed to knowing  you are not really getting the new drug)
\item<4-> The experimenter has the same frame of mind evaluating patients  from each group.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Leg Fracture Example}

In many cases, randomization cannot be achieved in that the  treatments being compared cannot be assigned, e.g., the study  involving women and leg fractures. When a new subject enters the  study (by having a car accident), we observe what gender they belong  to, instead of randomly assigning it. This is an example of  \textit{observational studies}.
\end{frame}

\begin{frame}[fragile]{Typical Reasons for Observational Studies}

{\footnotesize{
\begin{itemize}
\item<1-> Assigning treatment is impossible \\
E.g. to compare fracture rates between men and women, we  cannot randomize subjects into the comparison groups
\item<2-> Assigning treatment is unethical \\
E.g. to compare cancer rates of smokers and nonsmokers, we do  not want to \textit{randomize} subjects into smoker-nonsmoker comparison groups
\item<3-> Assigning treatment is impractical \\
E.g. the outcome is a rare event like cancer or stroke, and a  randomized trial would need too many subjects and too much  time.
\item<4-> In cases like these, a case-control study is generally the way to go.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Case-control Study}

{\footnotesize{
\textit{starts with the outcome} and then works backward to the type of treatment. For instance in the diet comparison trial, a case-control study would look for people in the population who lost weight, and then ask them what diet they used.

\vspace{3mm}

Case-control studies, compared to randomized controlled experiments,

\begin{itemize}
\item<1-> are frequently used because they are cheaper and easier to conduct;  
\item<2-> are less time-consuming to conduct;
\item<3-> are able to conclude a link or `association,' but are not able to prove  `causation;'
\item<4-> provide initial evidence that can generate resources for more rigorous  studies like double-blind randomized controlled trials.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Successful Story of a Case-control Study}

The first study formally linking lung cancer to smoking was a 1950  case-control study ``Smoking and Carcinoma of the Lung'' by Richard  Doll and A. Bradford Hill (British Medical Journal, 1950 September 30;  2(4682): page 739â€“748). This study led to numerous studies, and  consequently, it is now accepted by the scientific community that  smoking causes lung cancer.

\end{frame}

\begin{frame}[fragile]{Case-crossover Study}

allows subjects in the treatment group `cross over' to the control group  an vice versa. That is, each subject can be their own control.

\vspace{3mm}

A successful example: a 1997 study linking cell phone use to car  accidents: ``Association between cellular-telephone calls and motor  vehicle collisions'' by D.A. Redelmeier and R.J. Tibshirani (The New  England Journal of Medicine, 1997 Feb 13; vol 336, pp. 453â€“458).
\end{frame}

\begin{frame}[fragile]{iClicker Question 5.1}

According to ``Cumulative Use of Strong Anticholinergics and Incident  Dementia'' (JAMA, March 2015), from 10 years of tracking older adults  and their use of anticholinergic drugs (meant to reduce symptoms of  allergies, inability to sleep, anxiety, depression and bladder over-activity), the risk of Alzheimer's was 63 percent higher. What type  of study is this?

\begin{enumerate}
  \item randomized controlled experiment
  \item case-control study
  \item none of the previous
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 5.2}

Which of the following is \textit{false} about a case-control study when it is  compared to a randomized controlled trial?

\begin{enumerate}
  \item case-control study is less time-consuming to conduct
  \item case-control study is cheaper to conduct
  \item case-control study can be used to determine causation
  \item case-control study is easier to conduct
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 5.3}

A clinical trial was conducted in which 120 patients with similar clinical  features were randomly divided into a control group and a treatment  group, each consisting of 60 patients. What type of study this is?

\begin{enumerate}
  \item randomized controlled trial
  \item case-control study
  \item none of the previous
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 5.4}

{\footnotesize{
Western Michigan University offers a 1 credit course for freshmen, UNIV 1010, which teaches about university resources and study habits for success in college. It is an elective course and about half of the freshmen take it. WMU has studied the results by comparing the retention and GPAs of students who took this class against those who did not take this class. It was found that retention and GPAs were generally higher for those who took UNIV 1010. This evidence was put forth as proof that the course was successful and that it should be continued. \\
What potential source(s) of bias have not been accounted for by WMU?

\begin{enumerate}
  \item GPAs before college.
  \item Lack of randomization in subject selection for UNIV 1010
  \item Chosen majors of the students
  \item All the above
\end{enumerate}
}}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{STAT 1600 Ch. 6 The Normal Distribution}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT 1600 \\ Ch. 6 The Normal Distribution

\end{frame}

\begin{frame}[fragile]{Outline}

The Normal Distribution

\begin{itemize}
\item Normal Distribution and Z Score
\item Using the Normal or Z Curve
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Normal Distribution}

\begin{minipage}[ht]{5cm}

{\footnotesize{
\begin{itemize}
\item Normal distribution is denoted by N(mean,SD).
\item Standard normal has mean=0 and SD=1 and is denoted  by N(0, 1)z s
\item The mean gives the location of the line of symmetry and the standard deviation refers to the spread. 
\item \textbf{The area  under the curve always equals 1.}
\end{itemize}
}}
\end{minipage}
\begin{minipage}[ht]{5cm}


\includegraphics[width=5cm]{figure/LBL6a-1} 


\end{minipage}
\end{frame}

\begin{frame}[fragile]{Normal Distribution}

The normal or bell-shaped curve is helpful in calculating  probabilities

\begin{itemize}
\item 68\% of the data falls within -1 and +1 standard  deviations of the mean
\item 95\% falls between -2 and +2 standard deviations
\item 99.7\% falls between -3 and +3 standard deviations
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Normal Distribution}

\includegraphics[width=8cm]{chapters/chapter6/ext_figure/norm1.png}

\end{frame}

\begin{frame}[fragile]{Normal Distribution}

\includegraphics[width=7.5cm]{chapters/chapter6/ext_figure/norm2.png}

\end{frame}

\begin{frame}[fragile]{Normal Distribution}

\includegraphics[width=10cm]{chapters/chapter6/ext_figure/norm3.png}

\end{frame}

\begin{frame}[fragile]{Z-score}

{\small{
\begin{itemize}
\item<1-> To calculate area under curve of general N(mean, SD), calculate z  score (i.e., number of SD's above average/below the average).  For example, the area to  the left of X in this normal:

\item<2-> 
\begin{equation*}
  \texttt{calculate z-score of x} = z = \frac{x - \mu}{\sigma} 
\end{equation*}

\item<3-> To find the probability of a random variable, X, occurring in a  normal distribution, we make use of the normal distribution or  normal curve. Once we obtain a z-score using the formula  above we can find the probability of a data value occuring at or  below that value.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Z-score}

\begin{itemize}
\item To calculate area under curve of general N(mean, SD), calculate z  score (i.e., number of SD's above average/below the average).  For example, the area to  the left of X in this normal:

\item
\begin{equation*}
  \texttt{calculate z-score of x} = z = \frac{x - \mu}{\sigma} 
\end{equation*}

\item then area to the left of x in N(mean, SD) = area to the left of z in N(0,1)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Z-score}

{\small{
Let X =adult male height. Then X is N (70'', 4''). This is stating that  for this population the mean height in males is 70 inches and the  standard deviation is 4 inches. What is the probability that a male  is less than 6' tall (or 72 inches)?:
}}

\begin{minipage}[ht]{5cm}

\includegraphics[width=5cm]{chapters/chapter6/ext_figure/norm4.png}


\end{minipage}
\begin{minipage}[ht]{5cm}

\begin{eqnarray*}
z &=& \frac{x - \mu}{\sigma} \\
  &=& \frac{x - 70}{4} \\
  &=& \frac{72 - 70}{4} \\
  &=& 0.5
\end{eqnarray*}
\end{minipage}
\end{frame}

\begin{frame}[fragile]{Z-Score}

{\footnotesize{
Let X = adult male height. Then X is N (70'', 4''). This is stating that  for this population the average height in males is 70 inches and the standard deviation is 4 inches.  What is the probability that a male is less than 6' tall (or 72 inches)?:  }}
 
\begin{minipage}[ht]{5cm}

{\footnotesize{
\begin{eqnarray*}
z &=& \frac{X - \mu}{\sigma} \\
  &=& \frac{X - 70}{4} \\
  &=& \frac{72 - 70}{4} \\
  &=& 0.5 
\end{eqnarray*}
}}
\end{minipage}
\begin{minipage}[ht]{4cm}


\includegraphics[width=4cm]{figure/LBL6b-1} 

\end{minipage}

{\footnotesize{
A Z value of 0.5 corresponds to the area of 0.6915 (AUC).  This means the probability, $P(X \le 72$ inches), is 69.15\%
}}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{Stat1600 Ch 7 The Binomial Distribution}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT 1600 \\ Ch 7 The Binomial Distribution

\end{frame}

\begin{frame}[fragile]{Outline}

The Binomial Distribution  

\begin{itemize}
\item Binomial Random Variables
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Binomial Process and Binomial RV}


A sequence of (fixed) n observations is called a \textbf{binomial process} if

\begin{itemize}
\item<2-> each observation results in exactly one of two possible outcomes  (conveniently called \textit{success} and \textit{failure})
\item<2-> P (success) = p, and P (failure) = q = 1 - p for all observations  
\item<2-> observations are independent
\item<3-> X = total number of successes among the n observations is a  \textbf{binomial random variable} with parameters n and p and is denoted  $X \sim binomial(n, p)$
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Binomial Process and Binomial RV}


Example: What is the probability of rolling exactly two ones in 10  rolls of a die? (n, our sample size = 10)

There are several things you need to know:  

\begin{enumerate}
\item First Define Success: "Rolling a 1 on a single die"

\item Define the probability of success: (p): $p = \frac{1}{6} = 0.167$ 

\item Find the probability of failure: $(1 - p) = q = \frac{5}{6} = 0.833$ 

\item Define the X (or j) that we are investigating.  This is the number of successes out of the trials(or sample size, n):  Here it is two rolls out of 10 so $X = j = 2$
\end{enumerate}

\end{frame}

\begin{frame}[fragile]{Binomial Process and Binomial RV}

\begin{itemize}
\item<1-> Example: \textbf{What is the probability of rolling exactly two ones in 10  rolls of a die?}  Anytime a `1' appears it is a success.  Anytime any other number  (2, 3, 4, 5, 6) appears it is a failure.
\item<2-> We need to use the binomial probability distribution  function in order to solve for this:
\item<3->
\begin{equation*}
P[ X = j] = \frac{n!}{j! (n - j)!} p^j (1 - p)^{n - j}, 
\end{equation*}

\texttt{where j = 0, 1, 2, $\cdots$, n}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Binomial Process and Binomial RV}

In our example: \\
X = j = 2 and  n = 10 \\
p = (probability of success) = 1/6 = 0.167 \\
q = (probability of failure) = 1 - p = 1 - 0.167 = 0.833 \\
(Since q is the probability of failure in our example you can see it is also 5/6 as there are five other numbers the die could fall on.)
\end{frame}

\begin{frame}[fragile]{Using Formula to Compute Binomial Probability}

$X \sim binomial(n, p)$

\begin{eqnarray*}
P[X = 2] &=& \frac{10!}{2! (10 - 2)!} (.167)^2 (.833)^{10-2} \\
   &=& \frac{ 10 \times 9 \times 8!}{ (2 \times 1) (8!)} (.167)^2 (.833)^{8} \\
   &=& (45)(.167)^2 (.833)^{8} \\
   &=& 0.291 \texttt{ or } 29.1\%
\end{eqnarray*}

\end{frame}

\begin{frame}[fragile]{Examples of Binomial RV}

\begin{itemize}
\item A 5-question multiple-choice quiz has 5 choices on each question.
X = number of correct answers (success = correct) in the quiz by
guessing all.  Then $X \sim binomial( n = 5, p = 0.20)$.

\item Past experience: 40\% phone respondents agree to be interviewed  (success = a respondent agrees to be interviewed) for market  research survey. Of 50 reached by Reliable Research, X respondents agree to be interviewed. Then
$X \sim binomial(n = 50, p = 0.40)$.

\end{itemize}
\end{frame}

\begin{frame}[fragile]{Examples of Binomial RV}

\begin{itemize}

\item Suppose historical data shows that 20\% of buyers at Best Buy who purchase smart fitness and GPS watches also purchase the Geek Squadâ€™s extended protection plan (success = a buyer purchases extended protection plan). X extended protection plans were sold along with the 300 smart watches sold last quarter. Then $X \sim binomial(n = 300, p = 0.20)$.

\end{itemize}
\end{frame}

\begin{frame}[fragile]{iClicker Question 7.1}

The probability that a defective item is observed at a production line  is 0.02. A quality engineer, working at the production line, inspects  an item. What is the chance that the item is found to be non-defective?

\begin{enumerate}
\item 0.02
\item 1
\item 0.98
\item -0.02
\item none of the previous
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 7.2}

Over a long period of time in a large multinational corporation, 10\% of all sales trainees are rated as outstanding, 75\% are rated as excellent/good, 10\% percent are rated as satisfactory, and 5\% are considered unsatisfactory. What is the probability that a sales trainee is rated as not outstanding?

\begin{enumerate}
\item 0.05
\item 0.10
\item 0.25
\item 0.90
\item 0.95
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Outline}

The Binomial Distribution  

\begin{itemize}
\item Binomial Random Variables
\item Computing Binomial Probabilities Using a Formula
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Using Formula to Compute Bin. Prob.}

{\small{
\begin{itemize}
\item<1-> $X \sim binomial( n, p)$
\item<1->
\begin{equation*}
  P[X = j] = \frac{n!}{j! (n - j)!} p^j ( 1 - p)^{n - j}
\end{equation*}
\item<1-> \texttt{where j = 0, $\cdots$, n} and $n! = n \times (n-1) \times \cdots \times 1 $
\item<2-> Multiple-choice quiz: $X \sim binomial(5, 0.2)$, eg.,
\item<2->
\begin{eqnarray*}
  P[X = 2] &=& \frac{5!}{2! (5 - 2)!} 0.2^2 ( 1 - 0.2)^{5 - 2} \\
  &=& \frac{5 \cdot 4 \cdot 3!}{2 \cdot 1 (3!)} 0.2^2 \cdot 0.8^3 = 0.2048 
\end{eqnarray*}
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Best Buy Example, continued}

{\small{
Recall that historical data shows that 20\% (i.e., $p = 0.2$) of buyers at Best Buy purchase extended protection plans with smart watches. If ($n = 10$ smart watches were sold  in one day, what is the probability that ($j = 3$) extended protection plans were sold? Now, X , the number of extended protection plans sold along with 10 smart watches has $X \sim binomial(10, .2)$ distribution and hence

\begin{eqnarray*}
  P[X = 3] &=& \frac{10!}{3! (10 - 3)!} 0.2^3 ( 1 - 0.2)^{10 - 3} \\
  &=& \frac{10 \cdot 9 \cdot 8 \cdot 7!}{3 \cdot 2 \cdot 1 (7!)} 0.2^3 \cdot 0.8^7 \\
  &=& 0.2013 
\end{eqnarray*}
}}
\end{frame}

\begin{frame}[fragile]{Using Formula -- olympics swimmer eg.,}

{\small{
A swimmer competes in three events in the Summer Olympics. The  swimmer's winning/losing one event is independent of her result in any  other event. If the probability of winning any one event is 0.45, what is  the chance that she wins two or three events?  $X \sim binomial(3, 0.45)$

\begin{eqnarray*}
P[ X = 2 or X = 3] &=& P[X = 2] + P[X = 3] \\
&=& \frac{3!}{2! (1)!} 0.45^2 0.55^1 + \frac{3!}{1! (0)!} 0.45^3 0.55^0 \\
&=& 0.334125 + 0.091125 \\
&=& 0.42525
\end{eqnarray*}
}}
\end{frame}

\begin{frame}[fragile]{The â€˜Languageâ€™ of Probability}

\begin{itemize}
\item<1-> Note first that X , the number of successes, can only assume  values 0, 1, ..., n.
\item<2-> `only 2' or `exactly 2': P(X = 2)
\item<3-> `at most 3 or `no more than 3' or `3 or less': 
$P[X \le 3] = P(X = 0, 1, 2, \texttt{ or } 3) =$ \\ $P(X = 0) + P(X = 1) + P(X = 2) + P(X = 3)$

\item<4-> `at least 8' or `no less than 8' or `8 or more' if n=10:
$P[X \ge 8] =$  \\ $P[X = 8] + P[X = 9] + P[X = 10]$
\item<5-> etc.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{iClicker Question 7.3}

The probability that a defective item is observed at a production line  is 0.02. A quality engineer, working at the production line, goes to inspect the next 4 items.  What is the set of possible number of defectives?

\begin{enumerate}
\item {1,2,3,4}
\item {0,1,2,3,4}
\item {1,2}
\item {3,4}
\item none of the previous
\end{enumerate}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{STAT1600 Ch. 8 Sampling Distribution of the Proportion}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT1600 \\ Ch. 8 Sampling Distribution of the Proportion

\end{frame}

\begin{frame}[fragile]{Outline}

Distribution of the Sample Proportion  

\begin{itemize}
\item Best Buy Example
\item Theory
\item Law of Large Numbers for Sample Proportions
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Sampling Distribution of the Proportion}

\begin{itemize}
\item<1-> Suppose Best Buy sells 60 extended protection plans with 300 smart watches sold.

\item<2-> The protection plan sales rate is  $\frac{60}{300} = 0.20$.

\item<3-> Therefore, let X denote the number of successes out of a sample  of $n$ observations. Then $X$ is a binomial random variable with  parameters $n$ and $p$. Note that $p$ is the (population) proportion of  successes.

\item<4-> The (sample) proportion of successes, $\hat{p} = \frac{x}{n}$ in a sample is also a random variable.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Sampling Distribution of the Proportion}

\begin{itemize}
\item<1-> $\hat{p} = \frac{X}{n}$ = (number of successes) / (sample size)

\item<2-> For the binomial, X, the number of successes, is expected to be around $np$ give or take $\sqrt{ n p q}$.

\item<3-> For the proportion, $\hat{p}$ is expected to be $p = \frac{n \hat{p}}{n}$ give or take $\sqrt{ \frac{p q}{n}} = \frac{ \sqrt{n p q}}{n}$. 

\item<4->
\begin{table}
\centering
\begin{tabular}{@{} ccc @{}} \hline
Random Variable & Mean & SD \\ \hline
X & $np$ & $\sqrt{n p q}$ \\
$\hat{p}$ & p & $\sqrt{ \frac{p q}{n}}$ \\ \hline
\end{tabular}
\end{table}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Best Buy example, revisited}

\begin{itemize}
\item<1-> The number of protection plans sold is expected to be around $60 \pm 7$

\item<2-> The proportion of plans sold is expected to be around
\begin{equation*}
  \frac{60}{300} \pm \frac{7}{300} \texttt{ or } 0.2 \pm 0.02
\end{equation*}

\item<3-> The \textit{percentage} of plans sold is expected to be around 20\%  give or take 2\% (Note: percentage = proportion $\times$ 100\%)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Gamers Retro Rental Eg., revisited}

{\footnotesize{
\begin{itemize}
\item<1-> Historically, 5\% of videogame rentals from Gamers Retro Rental are returned late.
\item<2-> Gamers Retro Rental rented out 100 videogames yesterday. The percentage  that will be returned late should be around 5\%, give or take
\begin{equation*}
100\% \times \sqrt{ \frac{ 0.05 \times 0.95}{100}} \approx 2.2\%
\end{equation*}
\item<3-> Gamers Retro Rental  rented out 700 videogames yesterday. The percentage  that will be returned late should be around 5\%, give or take
\begin{equation*}
100\% \times \sqrt{ \frac{ 0.05 \times 0.95}{700}} \approx 0.8\%
\end{equation*}
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 8.1}

A study surveyed 100 students who took a standardized test. Among  these students, 43 said they would like math help. What is the sample  percentage of students needing math help?

\begin{enumerate}
\item 100\%
\item 43\%
\item 0.43\%
\item 1\%
\item cannot determine
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Law of Large Numbers}

\begin{itemize}
\item<1-> for sample proportions
\item<1-> The sample proportion tends to get closer to the true proportion as  sample size increases.

\item<2-> For the Best Buy Example:
\item<2-> Recall if Best Buy sold 300 protection plans then $sd = 0.02$. Note that  $p = 0.2$.

\item<3-> If Best Buy sold 1200 plans then,
\begin{equation*}
SD = \sqrt{ \frac{ 0.2 \cdot 0.8}{1200}} = 0.0115
\end{equation*}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Sampling Distn of Sample Proportion}

If Best Buy sold 100 protection plans with their smart watches last year, the percentage of watches sold with protection plans is expected to be around 20\% give or take 4\%.  Estimate the likelihood that it sold a protection plan with each smart watch  for more  than 25\% of those watches, in other words,

\begin{equation*}
  P[ \hat{p} > 0.25] = ?
\end{equation*}
\end{frame}

\begin{frame}[fragile]{Sample Proportion is approx. normal}

\begin{minipage}[ht]{6cm}

Given: $n = 100$ and $p = .2$ and 
$SD = \sqrt{ \frac{.2(.8)}{100}} = 0.04$ and
$P[ \hat{p} > 0.25] = ?$ 

Note that $\hat{p} \approx N( 0.2, 0.04)$

$z = \frac{0.25 - 0.2}{0.04} = 1.25$

{\small{
\begin{eqnarray*}
P[ \hat{p} > 0.25] & \approx & P[ Z > 1.25] \\
& \approx & 1 - P[Z < 1.25] \\
& \approx & 1 - .8944 \\
& \approx & 0.1056
\end{eqnarray*}
}}
\end{minipage} \hfill
\begin{minipage}[ht]{4cm}


\includegraphics[width=3.5cm]{figure/LBL8a-1} 


\end{minipage}
\end{frame}

\begin{frame}[fragile]{iClicker Question 6.2}

Recall that if Best Buy sold 100 smart watches last year, the percentage of  watches sold with extended protection plans is expected to be around 20\% give or take 4\%.  What is the chance that the percentage of plans sold with extended warranties is between  $12\% (= 20\% - 2 \times 4\%) \texttt{ and } 28\% (=  20\% + 2 \times 4\%$)?

\begin{enumerate}
\item 99.7\%
\item 95\%
\item 68\%
\item 75\%
\item cannot determine
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Outline}

% Distribution of the Sample Proportion  

Estimating Proportion

\begin{itemize}
 
\item<1-> Questions Asked About Population Proportion
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Questions Asked}

about the population proportion

\begin{itemize}
\item<1-> The population proportion p are generally unknown and are  estimated from the data.
\item<2-> Suppose we want to estimate the number of students planning to  attend graduate school.
  \begin{enumerate}[1]
   \item<3-> Will the sample proportion equal the population proportion? Yes or  No.
    \item<4-> If not, by how much will it miss?
  \end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Estimating the population proportion p}

\begin{itemize}
\item<1-> $\hat{p}$ is an estimate of the population proportion, i.e.,
\begin{equation*}
E[ \hat{p} ] = p
\end{equation*}

\item<2-> Our estimate misses it by the standard error of the proportion
\begin{equation*}
SE = \sqrt{ \frac{ \hat{p} (1 - \hat{p})}{n}}
\end{equation*}

\item<3-> Consider our example: $n = 40$ graduating seniors, $X = 6$ plan to  attend graduate school.

\begin{enumerate}[1]
  \item<4-> What is the proportion of graduating seniors planning to attend  graduate school?
  \item<5-> By how much will it miss the true population proportion?
\end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Estimating the pop. proportion -- Cont'd}

{\small{
\begin{itemize}
\item<1-> $\hat{p} = \frac{X}{n} = \frac{6}{40} = 0.15$

\item<2-> 
\begin{eqnarray*}
SE_{\hat{p}} &=& \sqrt{ \frac{\hat{p} (1 - \hat{p})}{n}} 
= \sqrt{ \frac{.15 \times .85}{40}} \\
&=& 0.056 
\end{eqnarray*}

\item<3-> What if 54 out of 360 students plan to go to graduate school. The  proportion of all students who plan to go to graduate school is  estimated as

\item<4-> $\hat{p} = \frac{54}{360} = 0.15$ with $SE_{\hat{p}} = \sqrt{ \frac{.15 \times .85}{360}} = .0188$

\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Estimating the pop. proportion -- Cont'd}

\begin{itemize}
\item<1-> The \textbf{population} proportion $p$ is estimated using the sample proportion $\hat{p}$,  i.e., $E[ \hat{p}] = p$.   

\item<2-> This estimate tends to miss by an amount called the $SE_{\hat{p}}$.

\item<3-> The $SE_{\hat{p}}$ is calculated as 
\begin{equation*}
SE_{\hat{p}} = \sqrt{ \frac{ \hat{p} ( 1 - \hat{p})}{n}}
\end{equation*}

\item<4-> As sample size increases, the $SE_{\hat{p}}$ decreases.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{iClicker Question 8.3}

Which of the following statements is true about the standard error of  the sample proportion?

\begin{enumerate}
\item The standard error increases when sample size  increases.
\item The standard error decreases when sample size  decreases.
\item The increase/decrease of sample size has no effect on  the value of the standard error.
\item The standard error decreases when sample size  increases.
\item None of the previous.
\end{enumerate}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{STAT 1600 Ch 9 Comparing Two Proportions,  Part 1 Difference in Proportions}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT 1600 \\ Ch 9 Comparing Two Proportions, \\ Part 1 Difference in Proportions

\end{frame}

\begin{frame}[fragile]{Outline}


Difference Between Independent Proportions  

\begin{itemize}
\item Example and Notation
\item Standard Error of Difference in Sample Proportions
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Change in Student Retention Rate}

\begin{itemize}
\item<1-> Has retention rate at WMU  changing?
\item<2-> A random sample of 200 entering students in 1989 $\Rightarrow$ 74\% were  still enrolled 3 years later.
\item<3-> Another random sample of 200 entering students in 1999 $\Rightarrow$ 66\% were still enrolled 3 years later.
\item<4-> An 8\% change in 3-year retention rate was observed.
\item<5-> The 8\% difference is based on random sampling, and is only an  estimate of the true difference.
\item<6-> What is the likely size of the error of estimation?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Notation}

A categorical variable with binary responses (`success' and `failure') is of  interest for two independent populations.

\begin{itemize}
\item<1-> Population 1 has proportion $p_1$ of successes.  
\item<2-> Population 2 has proportion $p_2$ of successes.
\item<3-> Sample of size $n_1$  is taken from population 1: $X$ successes observed in the sample with sample proportion $\hat{p_1} = \frac{X}{n_1}$
\item<4-> Sample of size $n_2$  is taken from population 2: $Y$ successes observed in the sample with sample proportion $\hat{p_2} = \frac{Y}{n_2}$
\item<5-> The two samples are independent.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Standard Error of Difference}

The SE (Standard Error) of the difference in the sample proportions of  two independent samples is

$$SE_{\hat{p_1} - \hat{p_2}} = \sqrt{ (SE_{\hat{p_1}})^2 + (SE_{\hat{p_2}})^2} $$

where

{\small{
$$ SE_{\hat{p_1}} = \sqrt{ \frac{ \hat{p}_1 ( 1 - \hat{p}_1)}{n_1}} $$

$$ SE_{\hat{p_2}} = \sqrt{ \frac{ \hat{p}_2 ( 1 - \hat{p}_2)}{n_2}} $$
}}
\end{frame}

\begin{frame}[fragile]{Change in Student Retention Rate}

{\footnotesize{
\begin{itemize}
\item<1-> For 1989 sample $\hat{p}_1 = 0.74$ give or take (i.e., with a standard error)
$$ SE_{\hat{p_1}} = \sqrt{ \frac{ 0.74 ( 0.26)}{200}} = \sqrt{0.000962} = 0.031 $$

\item<2-> For 1999 sample $\hat{p}_2 = 0.66$ give or take (i.e., with a standard error)
$$ SE_{\hat{p_2}} = \sqrt{ \frac{ 0.66 ( 0.34)}{200}} = \sqrt{0.001122} = 0.033 $$

\item<3-> and hence for the difference in sample proportions.
$$SE_{\hat{p_1} - \hat{p_2}} = \sqrt{ 0.000962 + 0.001122} = 0.0456 $$

\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Calculation of the $SE_{\hat{p}_1 - \hat{p}_2}$}

{\footnotesize{
\begin{itemize}
\item<1-> Calculate ($SE_1)^2$, the squared $SE_{\hat{p_1}}$
\begin{equation*}
  (SE_1)^2 =  \frac{ \hat{p}_1 (1 - \hat{p}_1)}{n_1}
\end{equation*}
keeping 6 decimal places to the right of the decimal point.  
\item<2-> Calculate ($SE_2)^2$, the squared $SE_{\hat{p_2}}$
\begin{equation*}
  (SE_2)^2 = \frac{ \hat{p}_2 (1 - \hat{p}_2)}{n_2} 
\end{equation*}
keeping 6 decimal places to the right of the decimal point.  
\item<3-> Calculate $(SE_1)^2 + (SE_2)^2$.
\item<4-> $SE_{\hat{p}_1 - \hat{p}_2} = \sqrt{(SE_1)^2 + (SE_2)^2}$

\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Calculation of the $SE_{\hat{p}_1 - \hat{p}_2}$}

Change in Retention Rate Example

\begin{eqnarray*}
(SE_1)^2 &=& \frac{.74 \times .26}{200} = 0.000962 \\
(SE_2)^2 &=& \frac{.66 \times .34}{200} = 0.001122 \\
(SE_1)^2 + (SE_2)^2 &=& 0.000962 + 0.001122 = 0.002084 \\
SE_{ \hat{p}_1 - \hat{p}_2} &=& \sqrt{0.002084} = 0.0456
\end{eqnarray*}
\end{frame}

\begin{frame}[fragile]{Outline}

Confidence Interval for Difference in Proportions  

\begin{itemize}
\item Confidence Interval for Difference in Proportions  
\item iClicker Questions
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Confidence Interval for $\hat{p}_1 - \hat{p}_2$}

{\small{
A 95\% confidence interval for the true difference $p_1 - p_2$ is

$$\hat{p}_1 - \hat{p}_2 \pm 1.96 \times SE_{ \hat{p}_1 - \hat{p}_2}$$

That is 

$$\hat{p}_1 - \hat{p}_2 \pm 1.96 \sqrt{ \frac{\hat{p}_1 (1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2 (1-\hat{p}_2)}{n_2}}$$

\textit{If the interval excludes zero (0), then we say that the difference in sample proportions is statistically significant.} \\ However, If the interval includes 0 then the difference is statistically insignificant.
}}
\end{frame}

\begin{frame}[fragile]{Change in Student Retention Rate}

{\small{
\begin{itemize}
\item<1-> Recall that the standard error of the difference in the sample  proportions is
$$SE_{\hat{p}_1 - \hat{p}_2} = 0.0456$$
\item<2-> So, a 95\% CI (confidence interval) for $p_1 - p_2$ is
$(0.74 - 0.66) \pm 1.96 \times 0.0456 = 0.8 \pm 0.089 \Rightarrow$ (-.009, 0.169) 
\item<3-> If we round it off to (-.01, .17), or, in percentages, (-1\%, 17\%), we say  that the drop in retention rate from 1989 to 1999 is between -1\% and  17\% with 95\% confidence. 
\item<4-> Note: 0\% is contained in this interval and  hence there is still a probability that there might not be a real change in retention rate, just chance variability.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 9.1}

A 95\% confidence interval was constructed for the difference in the  proportions $p_1 - p_2$ in two independent populations: (-0.08, 0.26).  Which of the following is true?

\begin{enumerate}
\item The difference in the proportions is significant.
\item $p_1$  differs from $p_2$ significantly.
\item The difference in the proportions is insignificant.
\item None of the previous.
\end{enumerate}

\end{frame}

\begin{frame}[fragile]{iClicker Question 9.2}

{\small{
A study of the television viewing preferences of children, each child is  asked if the Sesame Street is the program he or she likes the best  among others. Of 200 girls surveyed, 85 like Sesame Street the best;  of 100 boys surveyed, 30 like Sesame Street the best. A 95\%  confidence interval for the difference in the percentages of children like  the Sesame Street the best between girls and boys is (1.2\%,23.8\%).

\begin{enumerate}
\item Which of the following is true?
\item The two percentages differ significantly.
\item The two percentages do not differ significantly.
\item The two proportions do not differ significantly.
\item None of the previous.
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{Outline}

Statistical Significance  

\end{frame}

\begin{frame}[fragile]{Cooks or Chefs}

\begin{itemize}
\item According to a 2009 occupation survey by the Census Bureau, regular cooks were a separate classification from chefs or head cooks:

\vspace{3mm}

\begin{tabular}{@{} ccccc @{}} \hline
Occupation & Women & Men & Total & \% Women \\ \hline
Cooks & 441 & 762 & 1203 & 37 \\
Chefs & 45  & 245 & 290  & 16 \\ \hline
\end{tabular}

\item The difference in percentage is approximately 21\%.
\item Is the difference in percentages just luck of the draw, or due to something  else besides chance?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Cooks or Chefs -- Cont'd}

\begin{itemize}
\item If chance was at work, how likely we get a difference in proportions of  0.21?
\item The chance of this occurs is small $\Rightarrow < 0.0001$. That is, less than 1 in 10,000.  This chance of getting 0.21 by chance is called a P-value.
\item But how do we know that this P-value is less than 0.0001?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Cooks or Chefs -- Cont'd}

{\small{
\begin{itemize}
\item The SE for the difference in proportion is
$$ SE_{\hat{p}_1 - \hat{p}_2} = \sqrt{ \frac{ .37 \cdot .63}{1203} + \frac{ .16 \cdot .84}{290} } = 0.026 $$ 
\item And hence the chance to get a difference beyond $\pm 0.078$ (= 3SE ) is 0.003  (= 1 - .997 by the empirical rule), or 3 in 1,000.
\item Similarly, the chance to get a difference beyond $\pm 0.104$ (= 4SE ) is $0.00006 < 0.0001$, or less than 1 in 10,000.
\item Now, in our example, a difference of 0.21 is beyond 8 SE. This cannot be  just chance variability.  Something else is at work.
\item Note: the probability of 0.00006 above was obtained by computer.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Statistical Significance, The P-Value}

The general rule for P-value for the difference:

\begin{itemize}
\item If P-value $\le .05$, the difference is \textbf{statistically significant}.  (difference is at least 1.96SE in absolute value)
\item If P-value $\le .01$, the difference is called \textbf{highly significant}.  (difference is at least 2.58SE in absolute value)
\item If P-value $> .05$, the difference is \textbf{insignificant}. (difference is less  than 1.96SE in absolute value)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{iClicker Question 9.3}

A 95\% confidence interval was constructed for difference in the proportions $p_1 - p_2$ in two independent populations: (-0.04, 0.16). Which of the following is true?

\begin{enumerate}
\item The p-value $\le 0.05$, the difference is statistically significant.
\item The p-value $\le 0.01$, the difference is called highly significant.
\item The p-value $> 0.05$, the difference is insignificant.
\item None of the above.
\end{enumerate}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{Stat1600 Ch 9.3.2 Comparing Two  Proportions, Part 2 Risk Ratio}

\begin{frame}[fragile]{Statistics and Data Analysis}

Stat1600 \\ Ch 9.3.2 Comparing Two  Proportions, \\ Part 2 Risk Ratio

\end{frame}

\begin{frame}[fragile]{Outline}

Risk Ratio  

\begin{itemize}
\item Risk Ratio
\item iClicker Questions
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Hepatitis E Vaccine}

From the study `Safety and Efficacy of a Recombinant Hepatitis E  Vaccine' by Shrestha et al. in the New England Journal of Medicine in  March 2007 (Vol. 356 No. 9), the results were

\begin{tabular}{@{} cccc @{}} \hline
     & \multicolumn{2}{c}{Hepatitis E} \\
     & Yes & No & Total \\ \hline
Vaccine & 3 & 895 & 898 \\
Placebo & 66 & 830 & 896 \\ \hline
\end{tabular}

The vaccine efficacy, as reported in the article, was 95.5\% with a 95\%  confidence interval of \\ (85.6\%, 98.6\%). \\
How?

\end{frame}

\begin{frame}[fragile]{Risk ratio}

{\small{
Consider:
\vspace{2mm}

\begin{tabular}{@{} cccc @{}} \hline
     & \multicolumn{2}{c}{Disease} \\
     & Yes & No & Total \\ \hline
Exposure & a & b & a + b \\
No exposure & c & d & c + d \\ \hline
\end{tabular}

where Exposure = Exposure to treatment (i.e., Vaccine in this example).

\vspace{2mm}

The \textit{risk ratio} (or relative risk) is

\begin{equation*}
RR = \frac{ P[ Disease, exposure]}{ P[ Disease, No exposure]} = \frac{ \frac{a}{a+b}}{ \frac{c}{c+d}} 
\end{equation*}

and the \textit{efficacy} of the exposure is (1 - risk ratio) \\ if \texttt{risk ratio} $ \le 1$. 

}}
\end{frame}

\begin{frame}[fragile]{Hepatitis E Vaccine Eg., Cont'd}

\begin{equation*}
RR = \frac{ \frac{3}{898}}{ \frac{66}{896}} = 0.045 \texttt{ or } 4.5\%
\end{equation*}

\vspace{3mm}

That is, getting the vaccine reduces your risk to only 4.5\% of the  original. The efficacy of the vaccine is 95.5\% (= 100\% - 4.5\%)

\end{frame}

\begin{frame}[fragile]{Calculating a 95\% CI for RR}

{\small{
\begin{enumerate}
\item<1-> Calculate a 95\% confidence interval for ln(RR):
  \begin{enumerate}
  \item<2-> calculate ln(RR)
  \item<3-> calculate
  \begin{equation*}
    SE_{ln(RR)} = \sqrt{\frac{1}{a} + \frac{1}{c} - \frac{1}{a+b} - \frac{1}{c+d}}
  \end{equation*}
  \item<4-> calculate 95\% CI for ln(RR)
  \begin{equation*}
    (ln(RR) - 1.96 SE, ln(RR) + 1.96 SE )
  \end{equation*}
  \end{enumerate}
\item<5-> A 95\% confidence interval for RR is
\begin{equation*}
    (e^{ln(RR) - 1.96 SE}, e^{ln(RR) + 1.96 SE} )
  \end{equation*}
  
\item<6-> and RR is statistical significant if the interval excludes one (1).
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{Hepatits E Vaccine Example, Cont'd}

{\small{
\begin{enumerate}
\item<1-> Calculate a 95\% confidence interval for ln(RR):
  \begin{enumerate}
  \item<2-> calculate ln(RR) = ln(.045) = -3.101
  \item<3-> calculate
  \begin{eqnarray*}
    SE_{ln(RR)} &=& \sqrt{\frac{1}{3} + \frac{1}{66} - \frac{1}{3+898} - \frac{1}{66+896}}  \\
    &=& \sqrt{.3462} \\
    &=& 0.5884 
  \end{eqnarray*}
  \item<4-> calculate 95\% CI for ln(RR)
  \begin{eqnarray*}
    CI &=& (-3.101-1.96 \cdot .5884, -3.101+1.96 \cdot .5884) \\
    &=& (-4.254, -1.948)
  \end{eqnarray*}
  \end{enumerate}
\end{enumerate}  
}}
\end{frame}

\begin{frame}[fragile]{Hepatits E Vaccine Example, Cont'd}

\begin{enumerate}
\item<1-> A 95\% confidence interval for RR is
\begin{equation*}
    (e^{-4.254}, e^{-1.948} ) = (.014, .143)
  \end{equation*}
  
\item<2-> That is, with 95\% confidence, the relative risk of getting hepatitis with the vaccine is only 1.4\% to 14.3\% of placebo. In other words, the vaccine reduces your risk by as low as 85.7\% (=100\% - 14.3\%) or as high as 98.6\% (= 100\% - 1.4\%).
\end{enumerate}

\end{frame}

\begin{frame}[fragile]{iClicker Question 9.2.1}

In an observational study, a sample of 10000 smokers was taken, 50  were found to have lung cancer. Another sample of 10000 non-smokers was taken, only 2 have lung cancer. What is the relative  risk of having lung cancer for smokers versus non-smokers?

\begin{enumerate}
  \item 50
  \item 2
  \item 25  
  \item 100
  \item cannot determine
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 9.2.2}

In an observational study, a sample of 10000 smokers was taken, 50  were found to have lung cancer. Another sample of 10000 non-smokers was taken, only 2 have lung cancer. A 95\% confidence  interval for the relative risk of having lung cancer for smokers versus  smokers is (6.1, 102.5). Which of the following is true?

\begin{enumerate}
\item The proportion of smokers having lung cancer is  significantly different than that of non-smokers.
\item There is no difference between the two proportions.
\item cannot determine
\end{enumerate}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{Stat1600 Ch 9.3.3 Comparing Two  Proportions, Part 3 Odds Ratio}

\begin{frame}[fragile]{Statistics and Data Analysis}

Stat 1600 \\ Ch 9.3.3 Comparing Two  Proportions, Part 3 Odds Ratio

\end{frame}

\begin{frame}[fragile]{Outline}

\begin{itemize}
\item Odds Ratio
\item iClicker Questions
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Odds}

The odds that an event occurs is

{\small{
\begin{equation*}
Odds = \frac{ \texttt{Probability that an event occurs}}{ \texttt{Probability that event does not occur}} = \frac{p}{1 - p}
\end{equation*}
}}

\begin{table}[ht]
\centering
\begin{tabular}{@{} cc @{}} \hline
Probability & Odds \\
0.10 & $\frac{1}{9} = 0.11$ \\
0.20 & $\frac{1}{4} = 0.25$ \\
0.50 & $\frac{1}{1} = 1.00$ \\
0.80 & $\frac{4}{1} = 4.00$ \\
0.90 & $\frac{9}{1} = 9.00$ \\
\end{tabular}
\end{table}
\end{frame}

\begin{frame}[fragile]{iClicker Question 9.1}

{\small{
A clinical trial was conducted to study the efficacy of a new drug  intended to lower the LDL (low-density lipoprotein, a.k.a., bad  cholesterol). All study subjects showed a high LDL level at the baseline.  Of the 100 treated subjects, 80 of them showed reduction to normal  LDL level two weeks after treatment. What is the odds that a treated  subject was having a reduction in LDL to normal level after two weeks?

\begin{enumerate}
\item 0.25
\item 4
\item 80
\item 20
\item cannot determine
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{Outline}

\begin{itemize}
\item Odds Ratio
\item iClicker Questions
\end{itemize}
\end{frame}


\begin{frame}[fragile]{Odds Ratio}

When comparing two groups, the odds ratio is

\vspace{3mm}

\begin{equation*}
OR = \frac{\texttt{Odds of group 1}}{\texttt{Odds of group 2}}
\end{equation*}

\vspace{3mm}

It is easier to interpret an OR when it's greater than 1 and hence, when  $OR < 1$, exchange the roles of the groups above to get an $OR > 1$.
\end{frame}

\begin{frame}[fragile]{Hepatits E Vaccine Example, revisited}

{\footnotesize{
\begin{table}[ht]
\centering
\begin{tabular}{@{} cccc @{}} \hline
     & \multicolumn{2}{c}{Hepatitis E} \\
     & Yes & No & Total \\ \hline
     Placebo & 66 & 830 & 896 \\
     Vaccine & 3 & 895 & 898 \\ \hline
\end{tabular}
\end{table}

If we consider the placebo (i.e., unvaccinated) group as group 1, then

\begin{equation*}
Odds(Hep | Placebo) = \frac{ \frac{66}{896}}{ \frac{830}{896}} = \frac{66}{830} = .07952
\end{equation*}

\begin{equation*}
Odds(Hep | vaccine) = \frac{ \frac{3}{898}}{ \frac{895}{898}} = \frac{3}{895} = .00335
\end{equation*}

\begin{equation*}
Odds Ratio = \frac{\texttt{unvaccinated}}{\texttt{vaccinated}} = \frac{.07952}{.00335} = 23.7
\end{equation*}

So, the odds of getting hepatitis is about 24 times greater if you remain  unvaccinated.

}}
\end{frame}

\begin{frame}[fragile]{Hepatits E Vaccine Example, Cont'd}

Consider, 

{\footnotesize{
\begin{table}[ht]
\centering
\begin{tabular}{@{} cccc @{}} \hline
     & \multicolumn{2}{c}{Disease} \\
     & Yes & No & Total \\ \hline
     Group 1 & a & b & a + b \\
     Group 2 & c & d & c + d \\ \hline
\end{tabular}
\end{table}

The odds ratio is then 

\begin{equation*}
OR = \frac{a \times d}{b \times c}  = \frac{ success_1 \times failure_2}{ failure_1 \times success_2} = \frac{ success_1 / failure_1}{ success_2 / failure_2  }
\end{equation*}

where $successes_1$  = \# of `successes' (yes's) in group 1 and $failures_1$ = \# of `failures' (no's) in group 1;  \\ $successes_2$ = \# of `successes' (yes's) in group 2 and  $failures_2$  = \# of `failures' (no's) in group 2. \\
Note: assume $OR > 1$. If $OR < 1$ then switch the rows above and then  the new OR is the reciprocal of the old one.
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 9.2}

{\footnotesize{
A clinical trial was conducted to study the efficacy of a new drug  intended to lower the LDL (low-density lipoprotein, a.k.a., bad  cholesterol). All study subjects showed high LDL level at the baseline.  Of the 100 treated subjects, 80 of them showed reduction to normal  LDL level two weeks after treatment. On the other hand, of the 100  subjects who received placebo, only 10 showed reduction to normal  LDL level after two weeks. What is the odds ratio of the treatment  group versus the placebo group?

\begin{enumerate}
\item 36
\item 4
\item 9
\item 8
\item cannot determine
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{A 95\% Confidence Interval for Odds Ratio}

{\footnotesize{
\begin{enumerate}
\item<1-> Calculate a 95\% confidence interval for the ln odds ratio
  \begin{itemize}
  \item<2-> calculate ln odds ratio
    {\footnotesize{
    \begin{equation*}
    ln( OR) = \frac{ad}{bc}
    \end{equation*}
    }}
  \item<3-> calculate the standard error of ln(odds ratio)
    {\scriptsize{
    \begin{equation*}
    SE = \sqrt{\frac{1}{a} + \frac{1}{b} + \frac{1}{c} + \frac{1}{d} }
    \end{equation*}
    }}
  \item<4-> a 95\% CI for ln(OR):
    {\footnotesize{
    \begin{equation*}
      (ln(OR) - 1.96(SE), ln(OR) + 1.96(SE))
    \end{equation*}
    }}
  \end{itemize}

\item<5-> A 95\% confidence interval for $OR$ is
  {\footnotesize{
  \begin{equation*}
    (e^{ln(OR) - 1.96(SE)}, e^{ln(OR) + 1.96(SE)} )
  \end{equation*}
  }}
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{Hepatits E Vaccine Example, revisited}

{\small{
\begin{itemize}
  \item<1-> Recall that the odds ratio of placebo subjects getting hepatitis against that of vaccinated subjects is

  \item<2-> calculate ln odds ratio
    {\footnotesize{
    \begin{equation*}
    ln( OR) = \frac{66 \times 895}{830 \times 3} = 23.7
    \end{equation*}
    }}
  \item<3-> 95\% CI for ln(OR):
  \item<4->
    {\footnotesize{
    \begin{equation*}
      ln(OR) = ln(23.7) = 3.165
    \end{equation*}
    }}
    \item<5-> calculate the standard error of ln(odds ratio)
    {\footnotesize{
    \begin{equation*}
    SE = \sqrt{\frac{1}{66} + \frac{1}{830} + \frac{1}{3} + \frac{1}{895} } = .5923
    \end{equation*}
    }}
  \end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Hepatits E Vaccine Example, revisited}

{\small{
  \begin{itemize}

  \item<1-> a 95\% CI for ln(OR):
    {\footnotesize{
    \begin{equation*}
      (3.165 - 1.96(.5923), 3.165 + 1.96(.5923)) \Rightarrow ( 2.004, 4.326)
    \end{equation*}
    }}

  \item<2-> A 95\% confidence interval for $OR$ is
  {\small{
  \begin{equation*}
    (e^{2.004}, e^{4.326} ) \Rightarrow (7.4, 75.6)
  \end{equation*}
  }}

  \item<3-> So, with 95\% confidence, the odds of \textit{unvaccinated} subjects getting hepatitis is approximately between 7 and 76 times greater than that of the vaccinated subjects.

\end{itemize}
}}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{Stat 1600 Ch. 10 Sampling Distribution of the Mean}

\begin{frame}[fragile]{Statistics and Data Analysis}

Stat 1600 \\ Ch. 10 Sampling Distribution of the Mean

\end{frame}

\begin{frame}[fragile]{Outline}

Sampling Distribution of the Mean  

\begin{itemize}
\item Sample Mean Versus Individual Values  
\item Sampling From Normal Population  
\item iClicker Questions
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Intro to the Sampling Distr'n of the Mean}

\begin{itemize}
\item<1-> If we look at variability in the x variable (individual values) we would notice some extreme values
\item<2-> If we take a random sample of size n from the population we can calculate the sample mean, $\bar{X}$.
\item<3-> The mean for our sample has to account for extremes in  the data but if we take many more samples of the same size we would see the variability in the possible sample means will be less than the variability for the individual X values.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Intro to the Sampling Distr'n of the Mean}

\begin{itemize}
\item<1-> This is because any extreme value will be averaged with other values in the sample. 
\item<2-> Therefore, as you increase the size of the sample, you have  more information; consequently, the sample mean is more accurate.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Example}

Start with a population of numbers.

[ 1, 2, 3, 4, 5]

$$\texttt{Mean } \mu = 3, \texttt{SD } \sigma = 1.41$$

Consider the process of taking a random sample of size $n = 3$  from the box and calculating the sample mean $\bar{x}$. 

\begin{enumerate}
\item<1-> Sample 1: [2, 4, 5];  $\bar{x}_1 = 3.67$
\item<2-> Sample 2: [1, 3, 5];  $\bar{x}_2 = 3.00$
\item<3-> Sample 3: [1, 3, 4];  $\bar{x}_3 = 2.67$
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Example}

{\small{
Start with a population of numbers.

[ 1, 2, 3, 4, 5]  $\texttt{ Mean } \mu = 3, \texttt{ SD } \sigma = 1.41$

Consider the process of taking a random sample of size $n = 3$  from the box and calculating the sample mean $\bar{x}$. 

{\footnotesize{
\begin{itemize}
\item Sample 1: [2, 4, 5];  $\bar{x}_1 = 3.67$
\item Sample 2: [1, 3, 5];  $\bar{x}_2 = 3.00$
\item Sample 3: [1, 3, 4];  $\bar{x}_3 = 2.67$
\item Sample 4: [1, 4, 5];  $\bar{x}_4 = 3.33$
\item Sample 5: [2, 3, 4];  $\bar{x}_5 = 3.00$
\end{itemize}
}}

Notice the different values for $\bar{X}_i$!

The value we would get for $\bar{x}$ is random, depending on chance.  Different samples yield different values for $\bar{x}$. 
}}
\end{frame}

\begin{frame}[fragile]{Standard Error of the Mean}

Standard Error of the sample mean is the variation in $\bar{X}$:

\begin{equation*}
  \sigma_{\bar{x}} = SE_{\bar{x}} = \frac{SD}{\sqrt{n}}
\end{equation*}

where SD is the variability (the standard deviation) in the individual  values and $n$ is the sample size.

\vspace{3mm}

Note: The sample mean $\bar{X}$ has expected value of $\mu$ ( the population  mean). That is, the average of the sample means of all size-$n$ samples  is the population mean.

\end{frame}

\begin{frame}[fragile]{Sampling Distribution of a Sample Mean}

\begin{minipage}[ht]{5cm}

{\small{
The expected value of $\bar{x}$ is 
}}

$$ E[\bar{x}] = \mu $$

{\footnotesize{
The standard error of the mean is
}}

$$ SE = \frac{ \sigma}{ \sqrt{n}} $$

\end{minipage} \hfill
\begin{minipage}[ht]{5cm}


\includegraphics[width=4.5cm]{figure/LBL10a-1} 


\end{minipage}

The sampling distribution is approximately normal (recommend $n > 30$). 

\end{frame}

\begin{frame}[fragile]{Men's Height Example}

\begin{minipage}[ht]{5cm}

selecting one man

{\small{
Suppose that male's height is approximately: \\
$N(mean = 69, SD = 3)$. \\
Using empirical rule \\
$0.68 \approx P(66 \le X \le 72)$
}}
\end{minipage} \hfill
\begin{minipage}[ht]{5cm}


\includegraphics[width=4.5cm]{figure/LBL10b-1} 


\end{minipage}
\end{frame}

\begin{frame}[fragile]{Men's Height Example}

\begin{minipage}[ht]{5cm}

selecting nine men

{\small{
Nine ($n = 9$) men are randomly selected.  Now, \\ $SE = \frac{3}{\sqrt{9}}$.  Using empirical  rule, \\
$0.997 \approx P[66 \le X \le 72]$
}}
\end{minipage} 
\begin{minipage}[ht]{5cm}


\includegraphics[width=4.5cm]{figure/LBL10c-1} 


\end{minipage}
\end{frame}

\begin{frame}[fragile]{Menâ€™s Height Example; discussion}

Therefore, when considering sample sizes of 1 or 9, our probability  went from 68.27\% to 99.73\%.

\vspace{3mm}

The reason for this difference is that it is harder to get the mean height of 9 men to be less than 66 or greater than 72 versus for a single male

\end{frame}

\begin{frame}[fragile]{Distribution of the Sample Mean}

when sampling from normal population.

If a population has a normal shaped histogram with $mean = \mu$, and standard deviation, $SD = \sigma$, then $n$-member averages will have a normal shaped histogram with $mean = \mu$ and $SE_{\bar{x}} = \frac{\sigma}{\sqrt{n}}$.


If $X_1, X_2, \cdots , X_n$ are sampled from $N(\mu, \sigma)$ then

$$ X \sim N( \mu, \frac{\sigma}{\sqrt{n}})$$.

\end{frame}

\begin{frame}[fragile]{Sampling Distribution of a Sample Mean}

\begin{minipage}[ht]{5cm}

{\small{
The expected value of $\bar{x}$ is 
}}

$$ E[\bar{x}] = \mu $$

{\footnotesize{
The standard error of the mean is
}}

$$ SE = \frac{ \sigma}{ \sqrt{n}} $$

\end{minipage} \hfill
\begin{minipage}[ht]{5cm}


\includegraphics[width=4.5cm]{figure/LBL10d-1} 


\end{minipage}

The sampling distribution is approximately normal (recommend $n > 30$). 

\end{frame}

\begin{frame}[fragile]{Men's Height Example 1}

\begin{enumerate}[a]
\item<1-> $n = 1$; $P[X > 71] =?$; $z = \frac{71 - 69}{3} = 0.67$

{\footnotesize{
$P[ X > 71] = P[ z > 0.67] = 1 - P[ z \le 0.67] = 1 - .7486 = .2514$
}}
\item<2-> $n = 1$; $P[X > 71] = 0.2514 $
\item<3-> $n = 9$; $P[\bar{X} > 71] =?$; $SE = \frac{3}{\sqrt{9}} = 1$;  $z =  \frac{71 - 69}{1} = 2$

{\footnotesize{
$P[ X > 71] = P[ z > 2] = 1 - P[ z \le 2] = 1 - .9772 = .0228$
}}
\item<4-> $n = 9$; $P[\bar{X} > 71] =  0.0228 $
\item<5-> $n = 25$; $P[\bar{X} > 71] =?$; $SE = \frac{3}{\sqrt{25}} = .6$;  $z =  \frac{71 - 69}{.6} = 3.33$

{\footnotesize{
$P[ \bar{X} > 71] = P[ z > 3.33] = 1 - P[ z \le 3.33] = 1 - .9996 = .0004$
}}
\item<6-> $n = 25$; $P[\bar{X} > 71] =  0.0004 $

\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Men's Height Example 1}

\begin{enumerate}[a]
\item<1-> $n = 9$; $P[\bar{X} > a] =.9$; $a = ?$

Note that $P[ z \ge -1.28] = 0.8997 \approx 0.9$.


$P[ \bar{X} > a] = P\Big[ z > \frac{a - 69}{ \sqrt{ \frac{3}{\sqrt{9}}}} \Big] \approx .90$ \\
$z \approx -1.28$


{\footnotesize{
$ -1.28 = \frac{a - 69}{1} \Rightarrow a = 69 + 1(-1.28) = 67.72$
}}

\item<2-> $P[\bar{X} > a] = 0.9 \Rightarrow a = 67.72 $
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 10.1}

It is suggested that the substrate concentration ($mg/cm^3$) of influent to  a domestic-waste biofilm reactor is normally distributed with mean 0.30  and standard deviation of 0.06. A sample of 9 reactors is taken. What  is the chance that the mean substrate concentration of influent of  these reactors is in between $0.26 mg/cm^3$  and $0.34 mg/cm^3$?

\begin{enumerate}
\item 68\%
\item 90\%
\item 95\%
\item 99.7\%
\item none of the previous
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Outline}

Estimating the Population Mean $\mu$    
\begin{itemize}
\item Estimating the Population Mean $\mu$
\item iClicker Questions
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Estimating the Population Mean}

\begin{itemize}
\item The population mean $\mu$ is estimated using the sample mean $\bar{X}$.  \item This  estimate tends to miss by an amount called the standard error ($SE_{\bar{x}}$) of
the mean. 
\item This is calculated as $\frac{SD}{\sqrt{n}}$.  Note that SD is the sample standard deviation 
\item
\begin{equation*}
  SD = \sqrt{ \frac{\sum (X - \bar{X})^2 }{n - 1}}
\end{equation*}
\end{itemize}

\end{frame}

\begin{frame}[fragile]{WMU Undergraduates' Average GPA}

\begin{itemize}
\item<1-> Suppose a sample of $n = 25$ WMU students yielded an average GPA of $\bar{X} = 3.05$ and a standard deviation of 0.40. Then the WMU true population average GPA, $\mu$, is estimated by 3.05 with a standard error of $\frac{SD}{\sqrt{n}}$.  What is the SE? 
\item<2-> $\frac{SD}{\sqrt{n}} = \frac{0.40}{\sqrt{25}} = 0.08$
\end{itemize}
\end{frame}

\begin{frame}[fragile]{WMU Undergraduates' Average Stay}

\begin{itemize}
\item<1-> A sample of $n = 25$ graduating students were randomly selected and  asked about their length of stay. 
\item<2-> Suppose that the sample averaged 5.3 years, with an SD of 1.5 years. \item<3-> Then the true WMU average stay, $\mu$, is estimated as $\bar{X} = 5.3$ years give or take $SE = \frac{SD}{\sqrt{n}} = \frac{1.5}{\sqrt{25}} = 0.3$ years.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{WMU Undergraduates' Average Stay}

\begin{itemize}
\item<1-> A second sample of 100 students were interviewed. 
\item<2-> The mean and SD for the second sample were also 5.3 years and 1.5 years, respectively.  
\item<3-> Then the true average stay $\mu$ is estimated as $\bar{X} = 5.3$ years give or take $SE = \frac{SD}{\sqrt{n}} = \frac{1.5}{\sqrt{100}} = 0.15$ years. 
\item<4-> Effect of Sample Size on Standard Error
\item<5-> The standard error of the mean decreases like the square root of the  sample size.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{iClicker Question 10.2}

{\small{
The HDL (high-density lipoprotein, a.k.a., good cholesterol) among  adults is normally distributed. A sample of 25 adults was selected  which yielded a sample standard deviation of $5.3 mg/dL$. A second  sample of 100 adults was selected which also yielded a sample  standard deviation of $5.3 mg/dL$. Which of the following is true about  the SEs (standard errors of the mean) of the two samples? ($SE_1 = SE_{n=25}$, $SE_2 = SE_{n=100}$)

\begin{enumerate}
\item $SE_1 = 4 SE_2$
\item $SE_2 = 2 SE_1$
\item $SE_1 = 2 SE_2$
\item $SE_2 = 4 SE_1$
\item none of the previous
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{Outline}

Sampling Distribution of the Mean  

\begin{itemize}
\item Confidence Interval for Population Mean
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Confidence Interval for Pop. Mean}

A 95\% confidence interval for $\mu$

\begin{equation*}
  \bar{X} \pm 1.96 \frac{SD}{\sqrt{n}}
\end{equation*}

\begin{enumerate}
\item That is, first calculate the margin of error:
\begin{equation*}
ME = 1.96 \times SE = 1.96 \frac{SD}{\sqrt{n}}
\end{equation*}
\item Then a 95\% confidence interval is
\begin{equation*}
(\bar{X} - ME, \bar{X} + ME)
\end{equation*}
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{WMU Undergraduatesâ€™ Average GPA}

Recall that the sample of $n = 25$ students yielded a sample mean of $\bar{X} = 3.05$ with a standard error of $SE = 0.08$.  The margin of error is then $ME = 1.96 \times 0.08 = 0.157$. Hence a 95\% CI for the true average  GPA, $\mu$, is:

$$(3.05 - 0.157, 3.05 + 0.157) = (2.893, 3.207)$$.

Interpretation: based on the sample, we are 95\% confident that the  true mean GPA is in between 2.9 and 3.2, approximately.
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{Stat 1600 Ch. 11  Comparing Two Means}

\begin{frame}[fragile]{Statistics and Data Analysis}

Stat 1600 \\ Ch. 11  Comparing Two Means

\end{frame}

\begin{frame}[fragile]{Outline}

Comparing Two Means

\begin{itemize}
\item Comparing Means of Two Independent Populations  
\item Estimating the Difference
\item iClicker Questions  
\item The P-Value
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Two-Sample Problem}

Two \textit{independent} populations are to be compared for a characteristic,  either a quantitative meansurement or a categorical one.  A random  sample is taken from each population to study.  The samples are  independent.  In a controlled study, the subjects are selected with  uniformity with respect to known source(s) of variation (similar weight, similar health condition, etc).
\end{frame}

\begin{frame}[fragile]{Examples}

{\small{
\begin{itemize}
\item Is there ``grade inflation'' in WMU? How does the average GPA of  WMU students today compare with 10 years ago? Suppose a  random sample of 100 student records from 10 years ago yields a  sample average GPA of 2.90 with a standard deviation of 0.40.  A  random sample of 100 current students today yields a sample average of 2.98 with a standard deviation of .45. The difference  between the two sample means is $2.98 - 2.90 = .08$. Is this proof  that GPA's are higher today than 10 years ago?  Or the chance  variability is at work?
\item How does the reduction of BMI of the Atkins diet compare to that  of Zone diet at 12 months?
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Notation}

\begin{itemize}
\item<1-> Population 1 has mean $\mu_1$ and standard deviation $\sigma_1$ (usually  unknown).
\item<2-> Population 2 has mean $\mu_2$ and standard deviation $\sigma_2$ (usually  unknown).
\item<3-> Sample of size $n_1$ is taken from population 1: the sample mean is $\bar{X}_1$, the sample standard deviation is $SD_1$, and the standard error is $SE_1 = \frac{SD_1}{\sqrt{n_1}}$  
\item<4-> Sample of size $n_2$ is taken from population 2: the sample mean is $\bar{X}_2$, the sample standard deviation is $SD_2$, and the standard error is $SE_2 = \frac{SD_2}{\sqrt{n_2}}$
\item<5-> The two samples are independent.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Estimating the Difference in Means}

\begin{itemize}
\item<1-> of two independent populations: $\mu_1 - \mu_2$
\item<2-> Point estimate $\bar{X}_1 - \bar{X}_2$
\item<3-> Standard Error:
{\small{
\begin{equation*}
SE = \sqrt{ (SE_{\bar{x}_1})^2 + (SE_{\bar{x}_2})^2 } = \sqrt{ \frac{SD_1^2}{n_1} + \frac{SD_2^2}{n_2}}
\end{equation*}
}}
\item<4-> 95\% CI for $\mu_1 - \mu_2$
\begin{equation*}
(\bar{X}_1 - \bar{X}_2) \pm ME
\end{equation*}

where 
{\small{
\begin{equation*}
 ME = 1.96 \sqrt{ \frac{SD_1^2}{n_1} + \frac{SD_2^2}{n_2}}
\end{equation*}
}}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Statistical Significance}

\begin{itemize}
\item<1-> If the 95\% confidence interval for $\mu_1 - \mu_2$ \textbf{excludes zero (0)}, then we  say that the difference is \textbf{statistically significant} or that the mean for one group differs significantly than that for the other group.
\item<2-> If the 95\% confidence interval for $\mu_1 - \mu_2$ \textbf{includes zero}, then we say that the difference is \textbf{insignificant} or that there is no significant  difference between the two population means.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Difference in GPA Averages Example}

{\footnotesize{
Let the GPAs today be of group 1 and that of 10 years ago be of group 2.

\begin{itemize}
\item point estimate: $\bar{X}_1 - \bar{X}_2 = 2.98 - 2.90 = 0.08$

\item standard error:
\begin{equation*}
SE = \sqrt{ \frac{(.45)^2}{100} + \frac{(.40)^2}{100}} = 0.06
\end{equation*}

\item Margin of error:
\begin{equation*}
ME = 1.96 \times SE = 1.96 \times 0.06 = 0.118
\end{equation*}

\item 95\% CI for $\mu_1 - \mu_2$
\begin{equation*}
( 0.08 - 0.118, 0.08 + 0.118) \Rightarrow (-0.038, 0.198)
\end{equation*}

\item The interval \textbf{includes zero} and hence, the difference is \textbf{insignificant}.  Simple chance variability can be a viable explanation for the observed  difference.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Diet Comparison Example}

{\footnotesize{
\begin{itemize}
\item<1-> Consider Atkins and Zone diets at 12 months. Denote $\mu_1$ the mean  change in BMI for Zone diet group and $\mu_2$ the mean change in BMI for  Atkins diet group.

\item<2-> point estimate: $\bar{X}_1 - \bar{X}_2 = (-.53) - (-1.65 ) = 1.12$

\item<3-> standard error:
\begin{equation*}
SE = \sqrt{ \frac{(2.00)^2}{79} + \frac{(2.54)^2}{77}} = 0.367
\end{equation*}

\item<4-> Margin of error:
\begin{equation*}
ME = 1.96 \times SE = 1.96 \times 0.367 = 0.72
\end{equation*}

\item<5-> 95\% CI for $\mu_1 - \mu_2$
\begin{equation*}
( 1.12 - 0.72, 1.12 + 0.72) \Rightarrow (0.40, 1.84)
\end{equation*}

\item<6-> This CI excludes zero (0) so therefore the difference is statistically significant.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 11.1}

{\small{
A 95\% confidence interval for the difference in the means of a  numerical measurement on two independent populations was  calculated from two independent samples. The result is (1.2, 10.5).  Which of the following is true?

\begin{enumerate}
\item the confidence interval excludes 0 hence the difference is insignificant
\item the confidence interval includes 0 hence the difference is insignificant
\item the confidence interval includes 0 hence the difference is significant
\item the confidence interval excludes 0 hence the difference is significant
% \item none of the above
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 11.2}

{\small{
A 95\% confidence interval for the difference in the means of a  numerical measurement on two independent populations was  calculated from two independent samples. The result is (1.2, 10.5).  Which of the following is a correct interpretation of the confidence  interval?
}}
{\footnotesize{
\begin{enumerate}
\item we are 95\% confident that the difference in sample  means is between \\ 1.2 and 10.5
\item we are 95\% confident that the difference in the true  means is between \\ 1.2 and 10.5
\item there is 95\% chance that the difference in the true means  is between \\ 1.2 and 10.5
\item there is 95\% chance that the difference in sample means  is between \\ 1.2 and 10.5
\item none of the above
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 11.3}

What effect is there on the standard error of the difference in means  if the sample sizes are each quadrupled?

\begin{enumerate}
\item the standard error is likely to decrease
\item the standard error is likely to increase
\item there is no effect
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Computing the P-value for the Difference}

in means of two independent populations

For a two-tailed test for the difference in means we can use the z-table to indicate probabilities:

\begin{equation*}
  \texttt{P-value} = 2 \times \Big[ 1 - P \Big[ Z \le \frac{ \bar{X}_1 - \bar{X}_2}{SE} \Big]  \Big]
\end{equation*}
\end{frame}

\begin{frame}[fragile]{Diet Comparison Example, Cont'd}

\begin{itemize}
\item Is it viable to explain that the difference in changes in BMI of 1.12 is  due to chance variability?
\item Note that we take the difference in changes in BMI of 1.12 and divide by the SE 0.367 to get a z-value: 1.12/0.367 = 3.05 
\item If the true difference were zero (0), the chance to observe a value as far as $\pm$ 3.05 or more SE's away from the mean would be:
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Diet Comparison Example, Cont'd}

{\small{
\begin{itemize}
\item 
\begin{eqnarray*}
P(Z < -3.05 \texttt{ or } Z > 3.05) &=& 2 P(Z > 3.05) \\
  &=& 2 [1 - P(Z \le 3.05)] \\
  &=& 2 [1 - 0.9989] \\
  &=& 0.0022
\end{eqnarray*}

\item This is a very small chance making it hard to believe that the true difference is zero (0). 
\item Hence, we conclude that statistically, the two means are different.  Or we can say that the means are significantly different.
\end{itemize}
}}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{Stat 1600 Ch. 11.2  Comparing Two Means -- Paired Data}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT 1600 \\ Ch 11.2 Comparing Two Means -- Paired Data

\end{frame}

\begin{frame}[fragile]{Outline}

Paired Data

\begin{itemize}
\item Comparing Means in Paired Data  
\item (General) Paired Data
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Paired Data, Before-and-After Data}

{\small{
Data come in pairs, each subject was measured twice, before and  after.  Note that it's NOT two samples, it's one sample of subjects, each  measured twice. Weight Loss Example:
}}

\begin{table}
{\footnotesize{
\caption{Weight in pounds before and  after 12 months on diet}
\begin{tabular}{@{} ccc @{}} \hline
Subject & Before & After \\ \hline
1 & 180 & 155 \\
2 & 192 & 187 \\
3 & 205 & 194 \\
4 & 166 & 176 \\
5 & 220 & 205 \\
6 & 177 & 172 \\
7 & 189 & 173 \\ \hline
\end{tabular}
}}
\end{table}

\end{frame}

\begin{frame}[fragile]{Analysis of Paired Data}

{\small{
\begin{itemize}
\item It's WRONG to analyze the data using two-sample method. The proper  procedure is laid out below:
\item Calculate the pairwise differences in a consistent manner:
$d_i = \texttt{Before} - \texttt{After}, i = 1, \cdots , n$.
\item Treat the differences as one sample and
\item Mean difference: $\bar{D} = \frac{ d_1 + d_2 \cdots d_n}{n} $
\item Standard error $SE_{\bar{D}}$:
  {\scriptsize{
  \begin{equation*}
    SE = \frac{SD}{n} \texttt{  where } SD = SD_{d} = \sqrt{ \frac{ \sum (d_i - \bar{D})^2}{n - 1}}
  \end{equation*}
  }}
\item A 95\% CI for $\mu_d$:
  \begin{equation*}
    (\bar{D} \pm ME) \texttt{ where } ME = 1.96 \times SE
  \end{equation*}
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Analysis of Paired Data, Cont'd}

\begin{itemize}
\item If the confidence interval EXCLUDES zero (0), then the difference in means is statistically significant.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Weight Loss Example, revisited}

{\footnotesize{
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:49 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Before & After & Diff(d) & d - mean \\ 
  \hline
1 & 180.00 & 155.00 & 25.00 & 15.43 \\ 
  2 & 192.00 & 187.00 & 5.00 & -4.57 \\ 
  3 & 205.00 & 194.00 & 11.00 & 1.43 \\ 
  4 & 166.00 & 176.00 & -10.00 & -19.57 \\ 
  5 & 220.00 & 205.00 & 15.00 & 5.43 \\ 
  6 & 177.00 & 172.00 & 5.00 & -4.57 \\ 
  7 & 189.00 & 173.00 & 16.00 & 6.43 \\ 
   \hline
\end{tabular}
\end{table}


\begin{equation*}
SD = \sqrt{ \frac{ \sum (d_i - \bar{D})^2}{n - 1}} = 11.1
\end{equation*}

Hence, 
\begin{equation*}
SE = \frac{SD}{\sqrt{n}} = 4.2
\end{equation*}
}}
\end{frame}
 
\begin{frame}[fragile]{Weight Loss Example, cont'd}
  
The margin of error is
 \begin{equation*}
 ME = 1.96 \times SE = 1.96 \times 4.2 = 8.2
\end{equation*}

Hence a 95\% confidence interval for mean weight loss (i.e., mean  difference of Before and After) is

\begin{equation*}
( (9.6 - 8.2), (9.6 + 8.2) )  \Rightarrow  (1.4, 17.8)
\end{equation*}

% % (9.6 âˆ’ 8.2, 9.6 + 8.2) = (1.4, 17.8)
This CI \textbf{excludes} zero (0) and hence the mean weight loss is statistically \textbf{significant}.
\end{frame}

\begin{frame}[fragile]{iClicker Question 11.2.1}

Measurements of the left-hand and right-hand gripping strengths of 10  left-handed writers are recorded:

\begin{table}[ht]
\centering
{\small{
\begin{tabular}{@{} ccccccccccc @{}} \hline
  & \multicolumn{10}{c}{Person} \\
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
LH & 140&90&125&130&95&121&85&97&131&110 \\
RH & 138&87&110&132&96&120&86&90&129&100 \\ \hline
\end{tabular}
}}
\end{table}

\vspace{3mm}

Should this data set be treated as a paired data problem?

\begin{enumerate}
\item Yes.
\item No.
\item Cannot determine.
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 11.2.2}

{\scriptsize{
Measurements of the left-hand and right-hand gripping strengths of 10  left-handed writers are recorded:
}}

\begin{table}[ht]
\centering
{\footnotesize{
\begin{tabular}{@{} ccccccccccc @{}} \hline
  & \multicolumn{10}{c}{Person} \\
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
LH & 140&90&125&130&95&121&85&97&131&110 \\
RH & 138&87&110&132&96&120&86&90&129&100 \\ \hline
\end{tabular}
}}
\end{table}

{\footnotesize{
A 95\% confidence interval for $\mu_{left} - \mu_{right}$ is calculated and the result is  (0.22,6.98). Which statement below is true about the confidence interval?

\vspace{-3mm}

\begin{enumerate}
\item We are 95\% confident that the difference in sample means is  between 0.22 and 6.98.
\item There is a 95\% probability that the difference in the true mean  gripping strengths of the two hands is between 0.22 and 6.98.
\item We are 95\% confident that the difference in the true mean  gripping strengths is between 0.22 and 6.98.
% \item There is a 95\% probability that the difference in the sample  mean gripping strengths of the two hands is between 0.22  and 6.98.
% \item None of the previous.
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 11.2.3}

{\scriptsize{
Measurements of the left-hand and right-hand gripping strengths of 10  left-handed writers are recorded:
}}

\begin{table}[ht]
\centering
{\footnotesize{
\begin{tabular}{@{} ccccccccccc @{}} \hline
  & \multicolumn{10}{c}{Person} \\
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
LH & 140&90&125&130&95&121&85&97&131&110 \\
RH & 138&87&110&132&96&120&86&90&129&100 \\ \hline
\end{tabular}
}}
\end{table}

{\footnotesize{
A 95\% confidence interval for $\mu_{left} - \mu_{right}$ is calculated and the result is  (0.22,6.98). Which statement below is true about the confidence interval?

\vspace{-3mm}

\begin{enumerate}
\item The average gripping strength of the left hand differs  significantly than that of the right hand since the confidence  interval includes 0.
\item The average gripping strength of the left hand differs  significantly than that of the right hand since the confidence  interval excludes 0.
% \item The difference in average gripping strengths of the two hands  is insignificant since the confidence interval excludes 0.
\item The difference in average gripping strengths of the two hands  is insignificant since the confidence interval includes 0.
% \item None of the previous.
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{(General) Paired Data}

\begin{itemize}
\item<1-> Paired data are data in which natural matchings occur.
\item<2-> Even when we have two samples, if each observation in one  sample is uniquely matched to an observation in the other sample,  then we have paired data.
\item<3-> The analysis of such data should follow that of before-and-after  paired data.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Head Injury Criterion (HIC) Example}

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:49 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & Driver & Passenger \\ 
  \hline
Acura Integra 87 & 599.00 & 597.00 \\ 
  Audi 80 89 & 600.00 & 515.00 \\ 
  Chev Camaro 91 & 585.00 & 583.00 \\ 
  Ford Escort 87 & 551.00 & 418.00 \\ 
  Honda Accord LX 91 & 562.00 & 539.00 \\ 
  Toyota Corolla Fx 88 & 593.00 & 397.00 \\ 
  Volvo 740 LE 88 & 519.00 & 445.00 \\ 
   \hline
\end{tabular}
\end{table}

\end{frame}

\begin{frame}[fragile]{Head Injury Criterion (HIC) eg., Cont'd}

{\footnotesize{
\begin{itemize}
\item<1-> The differences of Head Injury Criterion (HIC) Driver -- Passenger: \\
2, 85, 2, 133, 23, 196, 74
\item<2-> Mean difference: $\bar{D} = 73.6$
\item<3-> Variation measures

\begin{minipage}[ht]{3.3cm}

{\scriptsize{
\begin{eqnarray*}
SD &=& \sqrt{ \frac{ \sum (d_i - \bar{D})^2}{n - 1}} \\ 
&=&  72.4
\end{eqnarray*}
}}
\end{minipage}
\begin{minipage}[ht]{3.3cm}

{\scriptsize{
\begin{eqnarray*}
SE &=& \frac{SD}{\sqrt{n}} \\
&=&   27.4
\end{eqnarray*}
}}
\end{minipage}
\begin{minipage}[ht]{3.3cm}

{\scriptsize{
\begin{eqnarray*}
ME &=&  1.96 \times SE \\
&=&   53.6
\end{eqnarray*}
}}
\end{minipage}

\vspace{-6mm}
\item<4-> A 95\% CI for mean difference in HICs (Driver - Passenger):
\begin{equation*}
  (73.6 - 53.6, 73.6 + 53.6) \Rightarrow (19.9, 127.2)
\end{equation*}

  which \textbf{excludes} zero (0) and hence the mean difference in HICs is  statistically \textbf{significant}.

\end{itemize}
}}
\end{frame}


%!Rnw root = ../../Master.Rnw

\section{Ch. 12 Testing Independence of Two Categorical  Variables}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT 1600 \\ Ch. 12 Testing Independence of Two Categorical  Variables

\end{frame}

\begin{frame}[fragile]{Outline}

Association/Independence of Categorical Variables  

\begin{itemize}
\item Association/Independence of Categorical Variables  
\item Testing for Statistical Association
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Association vs. Independence}

{\small{
If we are thinking, ``association and independence are the same,'' we are almost right. The difference is about design. In the test of independence, we collect observational units at random from a population, and the two categorical variables are observed for each unit. In the test of association, we collect the data by randomly sampling from each sub-group \textbf{separately}. (Say, 100 Democrat, 100 Republican, 100 Independent, and so on.) The null hypothesis is that each sub-group shares the same distribution of another categorical variable. (Say, ``chain smoker'', ``occasional smoker'', ``non-smoker''.)  The difference between these two tests is subtle yet important.
}}
\end{frame}

\begin{frame}[fragile]{Assoc./Indep. of two Cat. Var.}

{\small{
Association and Independence \\
Two variables A and B are said to be associated if the distribution of B  tends to change with the level of the A variable. Otherwise, they are  said to be not associated.

Each of the following are likely to be as stated:

\begin{itemize}
\item<1-> Gender and height are associated: males tend to be taller than  females.
\item<2-> GPA and height are independent: `height distribution tends to be the same for 3.0 students as well as 3.5 students.'
\item<3-> Shoe size and height are associated: taller people tend to wear larger-sized shoes.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{Example: HS GPA and College Attrition}

Is there an association between HS GPA (high school GPA) and college  attrition? A sample of $n = 189$ students entering a business school  program were followed as part of an attrition (i.e. drop out, transfer) study.  The students were cross classified according to Three (3) categories of attrition  outcomes and four (4) categories of HS GPA (the Observed frequency table):

{\small{
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & 2.0-2.5 & 2.5-3.0 & 3.0-3.5 & 3.5-4.0 \\ 
  \hline
not returned 2nd year & 25 & 3 & 4 & 6 \\ 
  not returned 3rd year & 14 & 7 & 4 & 6 \\ 
  returned 3rd year & 41 & 7 & 28 & 44 \\ 
   \hline
\end{tabular}
\end{table}

}}
\end{frame}

\begin{frame}[fragile]{GPA and Attrition Example, Cont'd}

If grades and attrition were independent, then the (Observed) frequency  table should have looked more like the Expected frequency table below:

{\small{
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & 2.0-2.5 & 2.5-3.0 & 3.0-3.5 & 3.5-4.0 \\ 
  \hline
not returned 2nd year & 16.00 & 3.00 & 7.00 & 11.00 \\ 
  not returned 3rd year & 13.00 & 3.00 & 6.00 & 9.00 \\ 
  returned 3rd year & 51.00 & 11.00 & 23.00 & 36.00 \\ 
   \hline
\end{tabular}
\end{table}

}}

How do we construct such a table?

\end{frame}

\begin{frame}[fragile]{Constructing Expected Frequency Table}

\begin{itemize}
\item<1-> Compute the row totals of the table.  
\item<2-> Calculate the column totals.
\item<3-> Calculate the grand total which is the sample size $n$. The total of  row totals should equal $n$ and the total of column totals should  equal $n$.
\item<4-> Calculate the expected frequency counts (these are E's, the  expected): For each cell,

{\small{
\begin{equation*}
E_{ij} = \frac{\texttt{row total (i)} \times \texttt{col total (j)} }{\texttt{Grand Total}}
\end{equation*}
}}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{GPA and Attrition Example, cont'd}

\begin{minipage}[ht]{6cm}

{\tiny{

O, Observed 

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
 & 1 & 2 & 3 & 4 & 5 \\ 
  \hline
1 & 25.00 & 3.00 & 4.00 & 6.00 & 38.00 \\ 
  2 & 14.00 & 7.00 & 4.00 & 6.00 & 31.00 \\ 
  3 & 41.00 & 7.00 & 28.00 & 44.00 & 120.00 \\ 
  4 & 80.00 & 17.00 & 36.00 & 56.00 & 189.00 \\ 
   \hline
\end{tabular}
\end{table}

}}
\end{minipage} \hfill
\begin{minipage}[ht]{5cm}

{\tiny{

E, Expected

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & 1 & 2 & 3 & 4 \\ 
  \hline
1 & 16.08 & 3.42 & 7.24 & 11.26 \\ 
  2 & 13.12 & 2.79 & 5.90 & 9.19 \\ 
  3 & 50.79 & 10.79 & 22.86 & 35.56 \\ 
   \hline
\end{tabular}
\end{table}

}}
\end{minipage}

{\small{
\begin{eqnarray*}
E_{11} &=& \frac{38 \times 30}{189} = 16.08 \\
E_{22} &=& \frac{31 \times 17}{189} = 2.79
\end{eqnarray*}
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 12.1}

{\small{
In a study, investigators classified adults by obesity and hypertension:

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Low & Average & High & Total \\ 
  \hline
Yes & 24 & 33 & 46 & 103 \\ 
  No & 109 & 101 & 87 & 297 \\ 
  Total & 133 & 134 & 133 & 400 \\ 
   \hline
\end{tabular}
\end{table}


Calculate the expected frequency of those who do not have  hypertension (No) and with the `Average' obesity category.

\begin{enumerate}
\item 34.5
\item 99.5
\item 34.2
\item 98.8
\end{enumerate}
}}
\end{frame}

\begin{frame}[fragile]{Measuring `Closeness' of Observed and Expected}

If the Observed (O) frequency table is close to (i.e, like) the Expected
(E) frequency table then the two categorical variables are independent.  Otherwise the variables are associated. \\
But how to measure this `closeness'/`farness' between O's and E's?

\vspace{3mm}

\textbf{Answer.}  We use the Chi-Square ($\chi^2$) statistic:

\vspace{3mm}

We conclude statistical association if $\chi^2 > b$ 

where $b$ is the critical value.

\end{frame}

\begin{frame}[fragile]{Computing Chi-square Statistic}

{\small{
\begin{itemize}
\item<1-> Create chi-square contribution table: each cell is of the form
{\footnotesize{
\begin{equation*}
\frac{(O - E)^2}{E}
\end{equation*}
}}

\vspace{-3mm}

\item<2-> Add up all $r \times c$ chi-square contributions to get the $\chi^2$ statistic.
{\footnotesize{
\begin{equation*}
\chi^2 = \sum \frac{(O - E)^2}{E}
\end{equation*}
}}

\vspace{-3mm}

\item<3-> Note that the degrees of freedom for the test is:
{\footnotesize{
\begin{eqnarray*}
df &=& (\texttt{one less no. of rows}) \times (\texttt{one less no. of columns}) \\
  &=& (r - 1) \times (c - 1)
\end{eqnarray*}
}}

\vspace{-6mm}

\item<4-> We conclude statistical association if $\chi^2 > b$ where $b$ is the critical value
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{(Critical Values of Chi-square Statistic}

\begin{minipage}[ht]{8cm}

The critical value $b$ of the chi-square statistic depends on the degrees  of freedom $df$ and is tabulated for selected values of $df$:

 \vspace{4mm}
 
In the GPA \& Attrition example, the degrees of freedom \\
$df = (3 - 1) \times (4 - 1) = 6$ and hence the critical value $b = 12.59$. If $\chi^2 > 12.59$ then the variables are dependent; otherwise, they are independent.

\end{minipage} \hfill
\begin{minipage}[ht]{3cm}

{\small{
\begin{tabular}{@{} cc @{}} \hline
$df$ & $b$ \\ \hline
1 & 3.84 \\
2 & 5.99 \\
3 & 7.81 \\
4 & 9.49 \\
5 & 11.07 \\
6 & 12.59 \\
7 & 14.07 \\
8 & 15.51 \\
9 & 16.92 \\
10 & 18.31 \\ \hline
\end{tabular}
}}
\end{minipage}

\end{frame}

\begin{frame}[fragile]{iClicker question 12.2}

For a 4 rows and 4 columns contingency table, what is the degrees of  freedom for the chi-square statistic?

\begin{enumerate}
\item 7
\item 8
\item 9
\item 15
\item 16
\end{enumerate}

\end{frame}

\begin{frame}[fragile]{iClicker question 12.3}

\begin{minipage}[ht]{8cm}

For a 2 rows and 4 columns contingency table. What is the critical value $b$?

\begin{enumerate}
\item 7.81
\item 9.49
\item 11.07
\item 12.59
\item 15.51
\end{enumerate}

\end{minipage} \hfill
\begin{minipage}[ht]{3cm}

{\small{
\begin{tabular}{@{} cc @{}} \hline
$df$ & $b$ \\ \hline
1 & 3.84 \\
2 & 5.99 \\
3 & 7.81 \\
4 & 9.49 \\
5 & 11.07 \\
6 & 12.59 \\
7 & 14.07 \\
8 & 15.51 \\
9 & 16.92 \\
10 & 18.31 \\ \hline
\end{tabular}
}}
\end{minipage}

\end{frame}

\begin{frame}[fragile]{GPA and Attrition Example, cont'd}

\begin{minipage}[ht]{6cm}

{\tiny{

O, Observed 

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
 & 1 & 2 & 3 & 4 & 5 \\ 
  \hline
1 & 25.00 & 3.00 & 4.00 & 6.00 & 38.00 \\ 
  2 & 14.00 & 7.00 & 4.00 & 6.00 & 31.00 \\ 
  3 & 41.00 & 7.00 & 28.00 & 44.00 & 120.00 \\ 
  4 & 80.00 & 17.00 & 36.00 & 56.00 & 189.00 \\ 
   \hline
\end{tabular}
\end{table}

}}
\end{minipage} \hfill
\begin{minipage}[ht]{5cm}

{\tiny{

E, Expected

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & 1 & 2 & 3 & 4 \\ 
  \hline
1 & 16.08 & 3.42 & 7.24 & 11.26 \\ 
  2 & 13.12 & 2.79 & 5.90 & 9.19 \\ 
  3 & 50.79 & 10.79 & 22.86 & 35.56 \\ 
   \hline
\end{tabular}
\end{table}

}}
\end{minipage}

\vspace{3mm}

We already have our Observed and Expected values so we can compute our Chi-Square test statistic.

\end{frame}

\begin{frame}[fragile]{GPA and Attrition Example, cont'd}

\begin{minipage}[ht]{6cm}

{\tiny{

O, Observed 

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
 & 1 & 2 & 3 & 4 & 5 \\ 
  \hline
1 & 25.00 & 3.00 & 4.00 & 6.00 & 38.00 \\ 
  2 & 14.00 & 7.00 & 4.00 & 6.00 & 31.00 \\ 
  3 & 41.00 & 7.00 & 28.00 & 44.00 & 120.00 \\ 
  4 & 80.00 & 17.00 & 36.00 & 56.00 & 189.00 \\ 
   \hline
\end{tabular}
\end{table}

}}
\end{minipage} \hfill
\begin{minipage}[ht]{5cm}

{\tiny{

E, Expected

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & 1 & 2 & 3 & 4 \\ 
  \hline
1 & 16.08 & 3.42 & 7.24 & 11.26 \\ 
  2 & 13.12 & 2.79 & 5.90 & 9.19 \\ 
  3 & 50.79 & 10.79 & 22.86 & 35.56 \\ 
   \hline
\end{tabular}
\end{table}

}}
\end{minipage}

\vspace{-4mm}

{\small{
\begin{itemize}
\item<1-> The $\chi^2$ is 
{\scriptsize{
\begin{eqnarray*}
\chi^2 &=& \frac{(25-16.08)^2}{16.08} + \frac{(3-3.42)^2}{3.42} + \cdots + \frac{(44-35.56)^2}{35.56} \\
&=& 4.9 + 0.1 + 1.4 + 2.5 + 0.1 + 6.4 + 0.6 + 1.1 + 1.9 + 1.3 + 1.2 + 2 \\
&=& 23.42  
\end{eqnarray*}
}}

\vspace{-6mm}

\item<2-> Is $\chi^2 > b$?  Yes, $23.5 > 12.59$ 

\item<3-> Therefore, we conclude that the HS GPA is dependent on  college attrition.
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{End Note}

If it is concluded that the two categorical variables are associated, it  \textbf{does NOT} establish causation.

\end{frame}









%!Rnw root = ../../Master.Rnw

\section{STAT 1600 Ch. 13 Correlation}

\begin{frame}[fragile]{Statistics and Data Analysis}

STAT 1600 \\ Ch. 13 Correlation

\end{frame}

\begin{frame}[fragile]{Outline}

Correlation Coefficient

\begin{itemize}
\item Association Between Two Numerical Measurements  
\item Scatterplots
\item Sample Correlation Coefficient
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Association Bet'n Two Numerical Vars.}

It is of interest to study the association (relationship) between two  Numerical variables. Examples abound:

\begin{itemize}
\item<1-> How is the height of the adult firstborn son related to father's height? \item<2-> How does the household expenditure vary with income?
\item<3-> Does blood pressure depend on age in adults? In what manner?  
\item<4-> What is the relationship between advertising expenditures and sales?  
\item<5-> What is the relationship between height and weight in young children.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Cor. Coef. Measures Linear Relationship}

(Linear) Correlation coefficient is used to measure the strength of linear  association between two quantitative variables. The population correlation  coefficient is denoted by $\rho$.

\begin{itemize}
\item<1-> $ -1 \le \rho \le 1 $
\item<2-> 

\begin{table}[ht]
{\footnotesize{
\caption{Linear Relationship as measured by $\rho$}
\begin{tabular}{@{} ccccccc @{}} \hline
Strong(-) & $\leftarrow$ & weak & No & weak & $\rightarrow$ & Strong(+) \\ \hline
-1 & -0.65 & -0.35 & 0 & +0.35 & +0.65 & 1 \\ \hline
\end{tabular}
}}
\end{table}

\item<3-> downward linear relationship if $\rho < 0$.
\item<4-> upward linear relationship if $\rho > 0$. 
\item<5-> no linear relationship if $\rho = 0$. 
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Interpretation and Cautions}

\begin{itemize}
\item<1-> Correlation measures linear association only.
\item<2-> A zero correlation implies only that the two measurements are not  linearly associated, it does not imply that there is no relationship  between these two measurements.
\item<3> Correlation does not imply causation: The number of deaths per  100,000 in England for a year in the late 1800's was recorded along  with the number of church weddings (in thousands) for several years.  The results are shown in the plot below.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Interpretation and Cautions}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=9cm]{chapters/chapter13/figure/fig1.png} % requires the graphicx package
   % \caption{example caption}
   % \label{fig:example}
\end{figure}

\end{frame}

\begin{frame}[fragile]{iClicker Question 13.1}

{\small{
The scatterplot of two numerical measurements x  and y is given on the right. Which of the following  statements is true?
}}

\vspace{3mm}

\begin{minipage}[ht]{6cm}

{\footnotesize{
\begin{enumerate}
\item There is no relationship between x and y since the correlation is zero.
\item There is no linear association  between x and y due to zero  correlation.
\item The change in x value causes the  change in y value.
\item There is upward linear relationship  between x and y .
\item There is downward linear relationship  between x and y .
\end{enumerate}
}}
\end{minipage} \hfill
\begin{minipage}[ht]{4cm}



\includegraphics[width=4cm]{figure/LBL13a-1} 

\end{minipage}
\end{frame}

\begin{frame}[fragile]{iClicker Question 13.2}

{\small{
Astringency is the quality in a wine that makes the wine drinker's mouth feel slightly rough, dry, and puckery.  The researchers reported looked at the relationship between perceived astringency and tannin concentration.  Which of the following  statements is true?
}}

\vspace{3mm}

\begin{minipage}[ht]{6cm}

{\footnotesize{
\begin{enumerate}
\item There is no relationship between  astringency(x) and perceived(y).
\item There is a downward linear  relationship between astringency(x) and perceived(y).
\item There is a upward linear relationship  between astringency(x) and perceived(y).
\item None of the above is true.
\end{enumerate}
}}
\end{minipage} \hfill
\begin{minipage}[ht]{4cm}



\includegraphics[width=4cm]{figure/LBL13b-1} 

\end{minipage}
\end{frame}

\begin{frame}[fragile]{iClicker Question 13.3}

The correlation between the cheese price and the median house  selling price for the state of Wisconsin from year 1960 to year 2000  was found to be 0.65. Which statement is false?

\begin{enumerate}
\item There is a upward linear relationship between the two  measurements.
\item The increase in median house selling price causes the  increase in cheese price.
\item The linear relationship is moderate.
\item The increase in median house selling price is positively  associated with the increase in cheese price.
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{iClicker Question 13.4}

Which value below is not a correlation coefficient?

\begin{enumerate}
\item -0.999
\item -0.75
\item 0
\item 0.99
\item 1.2
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Importance of Scatterplots}

To study the association between a pair of numerical measurements, a  sample of $n$ pairs of these measurements is taken. To inspect the  association between these measurements, a scatterplot provides an  excellent visual rendering of these n pairs of measurements.

\end{frame}

\begin{frame}[fragile]{Oil-exporter Example}

{\small{
In the world bank 85 data (chapter 1), we would like to measure the linear  association between birth rate (y) and per capita gross national product  (x) for the four high-income oil exporters. The data:
}}

{\small{
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & GNP & Birth rate \\ 
  \hline
Libya & 7 & 45 \\ 
  Saudi Arabia & 9 & 42 \\ 
  Kuwait & 14 & 34 \\ 
  United Arab Emirates & 19 & 30 \\ 
   \hline
\end{tabular}
\end{table}

}}

{\small{
\begin{itemize}
\item The values of birth rate range from 30 to 45.

\item The values of GNP range from 7,170 to 19,270. This range is  contained in (6,000, 20,000) (the latter to be plotted).
\end{itemize}
}}
\end{frame}

\begin{frame}[fragile]{(Oil-exporter Example: Scatterplot}


\includegraphics[width=7cm]{figure/LBL13d-1} 


\end{frame}

\begin{frame}[fragile]{Correlation is Not Robust}

Correlation coefficient is not a robust measure since it is sensitive to  outliers: for the data below

\begin{minipage}[ht]{5cm}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=5cm]{chapters/chapter13/figure/fig2.png} % requires the graphicx package
   % \caption{example caption}
   % \label{fig:example}
\end{figure}

\end{minipage}
\begin{minipage}[ht]{6cm}

\begin{table}[ht]
{\small{
\caption{The Corr. Coef. for various cases:}
\begin{tabular}{@{} rl @{}} \hline
-0.80 & all but obs 18, 28 \\
-0.69 & all but obs 28 \\
-0.34 & all but obs 18 \\
-0.29 & for full data \\
0.04  & all but obs 10, 18, 28 \\
0.17  & all but obs 10, 28 \\
0.61  & all but obs 10 \\
0.64  & all but obs 10, 18 \\ \hline
\end{tabular}
}}
\end{table}
\end{minipage}
\end{frame}

\begin{frame}[fragile]{Calculating the Correlation Coefficient}

\begin{itemize}
{\small{
  \item While keeping the same order of the $n$ pairs, do the following for $x$
values and for $y$ values separately:
  \begin{itemize}
  \item Use 3-column format to compute sample mean and standard  deviation.
  \item Add 4th column containing the standardized variable values (divide  the second column of deviations by standard deviation).
  \end{itemize}
\item Copy the standardized variable values for $x$ and for $y$ to a  separate table. Be sure to keep the same order of the $n$ pairs.
\item Add a column of the products of the standardized variable values.  
\item Total this new column to get the numerator of $r$.
\item Divide the value in the previous step by $n - 1$ to get $r$.
}}
\end{itemize} 
\end{frame}

\begin{frame}[fragile]{Oil-exporter Example}

{\footnotesize{
In the world bank 85 data (chapter 1), we would like to measure the linear  association between birth rate (y) and per capita gross national product  (x) for the four high-income oil exporters. The data:
}}

{\footnotesize{
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & GNP & Birth rate \\ 
  \hline
Libya & 7 & 45 \\ 
  Saudi Arabia & 9 & 42 \\ 
  Kuwait & 14 & 34 \\ 
  United Arab Emirates & 19 & 30 \\ 
   \hline
\end{tabular}
\end{table}

}}

\begin{itemize}
{\small{
\item The values of birth rate range from 30 to 45.

\item The values of GNP range from 7,170 to 19,270. This range is  contained in (6,000, 20,000) (the latter to be plotted).
\item How do we find the correlation coefficient for these two numeric variables?
}}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Oil-exporter Example: Correlation, step 1}

\begin{minipage}[ht]{6cm}

{\footnotesize{
Birth Rate:

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Y & Diff & Diff\_sq & Zy \\ 
  \hline
1 & 7.17 & -5.27 & 27.80 & -0.95 \\ 
  2 & 8.85 & -3.59 & 12.91 & -0.65 \\ 
  3 & 14.48 & 2.04 & 4.15 & 0.37 \\ 
  4 & 19.27 & 6.83 & 46.61 & 1.24 \\ 
   \hline
\end{tabular}
\end{table}

}}
\end{minipage}
\begin{minipage}[ht]{5cm}

{\scriptsize{
\begin{eqnarray*}
\bar{Y} &=& \frac{ \sum Y_i}{n} \\
Diff &=& Y_i - \bar{Y} \\
Diff_{sq} &=& \sum (Y_i - \bar{Y})^2 \\
SD_y &=& \sqrt{ \frac{ \sum ( Y_i - \bar{Y})^2}{n - 1}} \\
Zy &=& \frac{(Y_i - \bar{Y})}{SD_y}
\end{eqnarray*}
}}
\end{minipage}

\end{frame}

\begin{frame}[fragile]{Oil-exporter Example: Correlation, step 2}

\begin{minipage}[ht]{6cm}

{\footnotesize{
GNP:

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & X & Diff & Diff\_sq & Zx \\ 
  \hline
1 & 45.00 & 7.25 & 52.56 & 1.04 \\ 
  2 & 42.00 & 4.25 & 18.06 & 0.61 \\ 
  3 & 34.00 & -3.75 & 14.06 & -0.54 \\ 
  4 & 30.00 & -7.75 & 60.06 & -1.12 \\ 
   \hline
\end{tabular}
\end{table}

}}
\end{minipage}
\begin{minipage}[ht]{5cm}

{\scriptsize{
\begin{eqnarray*}
\bar{X} &=& \frac{ \sum X_i}{n} \\
Diff &=& X_i - \bar{X} \\
Diff_{sq} &=& \sum (X_i - \bar{X})^2 \\
SD_x &=& \sqrt{ \frac{ \sum ( X_i - \bar{X})^2}{n - 1}} \\
Zx &=& \frac{(X_i - \bar{X})}{SD_x}
\end{eqnarray*}
}}
\end{minipage}

\end{frame}

\begin{frame}[fragile]{Oil-exporter Example: Correlation, step 3}

Now, calculate the correlation using standardized variable values:


% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Zx & Zy & Zx * Zy \\ 
  \hline
1 & 1.04 & -0.95 & -1.00 \\ 
  2 & 0.61 & -0.65 & -0.40 \\ 
  3 & -0.54 & 0.37 & -0.20 \\ 
  4 & -1.12 & 1.24 & -1.38 \\ 
   \hline
\end{tabular}
\end{table}


\end{frame}

\begin{frame}[fragile]{Sample Correlation Coefficient}

{\footnotesize{
The two measurements are observed in n pairs:
$(x_1, y_1), (x_2, y_2), \cdots , (x_n, y_n)$. It is always recommended to plot these $n$  pairs in a scatterplot. The sample correlation (known as Pearson's  correlation coefficient), denoted by $r$ , can be computed by
}}

{\scriptsize{
\begin{eqnarray*}
  r &=& \frac{ \texttt{ Sum(products of standardized variables)}}{\texttt{one less number of pairs}} \\
  &=& \frac{ \sum \Big(\frac{(X - \bar{X})}{SD_x} \times \frac{(Y - \bar{Y})}{SD_y} \Big) }{n - 1} \\
  &=& \frac{ \sum (Z_x \times Z_y)}{n - 1}
\end{eqnarray*}
}}

\vspace{-6mm}

{\footnotesize{
where $\bar{X}$ and $SD_x$ are the sample mean and standard deviation for $x$  values, and $\bar{Y}$ and $SD_y$ are the sample mean and standard deviation for $y$ values.
}}

\end{frame}

\begin{frame}[fragile]{Oil-exporter Example: Correlation, step 3}

{\small{
Now, calculate the correlation using standardized variable values:
}}

{\footnotesize{
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Sat Jul 28 20:07:50 2018
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Zx & Zy & Zx * Zy \\ 
  \hline
1 & 1.04 & -0.95 & -1.00 \\ 
  2 & 0.61 & -0.65 & -0.40 \\ 
  3 & -0.54 & 0.37 & -0.20 \\ 
  4 & -1.12 & 1.24 & -1.38 \\ 
   \hline
\end{tabular}
\end{table}

}}

\vspace{-6mm}

{\footnotesize{
\begin{eqnarray*}
sumZ &=& \sum Zx * Zy = -2.9734107 \\
r    &=& \frac{ -2.9734107}{ (4 - 1)} = -0.9911369
\end{eqnarray*}
}}

{\small{
GNP and birth rate exhibit a strong negative (or downward) linear  relationship..
}}
\end{frame}

\begin{frame}[fragile]{iClicker Question 13.5}

Which of the following graphs has the strongest negative correlation?

\begin{minipage}[ht]{4cm}

\begin{enumerate}[A]
\item Car Weight
\item R/S
\item Ave.Temp.
\item Square Feet
\end{enumerate}
\end{minipage}
\begin{minipage}[ht]{6cm}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=6cm]{chapters/chapter13/figure/fig3.png} % requires the graphicx package
   % \caption{example caption}
   % \label{fig:example}
\end{figure}
\end{minipage}
\end{frame}




% \printbibliography
%\bibliographystyle{plain}
%\bibliography{chapters/mybibliography}   % name your BibTeX data base

% \section{Index}

% \printindex

\end{document}
